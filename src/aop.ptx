.version 7.7
.target sm_80
.address_size 64




















.visible .entry _Z25compute_final_beta_kernelILi128EEvPKiPd(
.param .u64 _Z25compute_final_beta_kernelILi128EEvPKiPd_param_0,
.param .u64 _Z25compute_final_beta_kernelILi128EEvPKiPd_param_1
)
.maxntid 128, 1, 1
{
.reg .pred %p<5>;
.reg .b32 %r<6>;
.reg .f64 %fd<10>;
.reg .b64 %rd<9>;

	.shared .align 8 .b8 _ZZ25compute_final_beta_kernelILi128EEvPKiPdE5lsums[24];

ld.param.u64 %rd3, [_Z25compute_final_beta_kernelILi128EEvPKiPd_param_0];
ld.param.u64 %rd4, [_Z25compute_final_beta_kernelILi128EEvPKiPd_param_1];
cvta.to.global.u64 %rd1, %rd4;
cvta.to.global.u64 %rd5, %rd3;
ld.global.nc.u32 %r2, [%rd5];
setp.eq.s32 %p1, %r2, 0;
mov.u32 %r1, %tid.x;
mul.wide.u32 %rd6, %r1, 8;
add.s64 %rd2, %rd1, %rd6;
@%p1 bra $L__BB0_3;

setp.gt.u32 %p2, %r1, 2;
@%p2 bra $L__BB0_7;

mov.u64 %rd7, 0;
st.global.u64 [%rd2], %rd7;
bra.uni $L__BB0_7;

$L__BB0_3:
ld.global.f64 %fd1, [%rd2];
ld.global.f64 %fd2, [%rd2+1024];
ld.global.f64 %fd3, [%rd2+2048];
setp.ne.s32 %p3, %r1, 0;
@%p3 bra $L__BB0_5;

mov.u64 %rd8, 0;
st.shared.u64 [_ZZ25compute_final_beta_kernelILi128EEvPKiPdE5lsums], %rd8;
st.shared.u64 [_ZZ25compute_final_beta_kernelILi128EEvPKiPdE5lsums+8], %rd8;
st.shared.u64 [_ZZ25compute_final_beta_kernelILi128EEvPKiPdE5lsums+16], %rd8;

$L__BB0_5:
bar.sync 0;
mov.u32 %r3, _ZZ25compute_final_beta_kernelILi128EEvPKiPdE5lsums;
atom.shared.add.f64 %fd4, [%r3], %fd1;
add.s32 %r4, %r3, 8;
atom.shared.add.f64 %fd5, [%r4], %fd2;
add.s32 %r5, %r3, 16;
atom.shared.add.f64 %fd6, [%r5], %fd3;
bar.sync 0;
@%p3 bra $L__BB0_7;

ld.shared.f64 %fd7, [_ZZ25compute_final_beta_kernelILi128EEvPKiPdE5lsums];
st.global.f64 [%rd1], %fd7;
ld.shared.f64 %fd8, [_ZZ25compute_final_beta_kernelILi128EEvPKiPdE5lsums+8];
st.global.f64 [%rd1+8], %fd8;
ld.shared.f64 %fd9, [_ZZ25compute_final_beta_kernelILi128EEvPKiPdE5lsums+16];
st.global.f64 [%rd1+16], %fd9;

$L__BB0_7:
ret;

}

.visible .entry _Z27compute_partial_sums_kernelILi128EEviPKdPd(
.param .u32 _Z27compute_partial_sums_kernelILi128EEviPKdPd_param_0,
.param .u64 _Z27compute_partial_sums_kernelILi128EEviPKdPd_param_1,
.param .u64 _Z27compute_partial_sums_kernelILi128EEviPKdPd_param_2
)
.maxntid 128, 1, 1
{
.reg .pred %p<4>;
.reg .b32 %r<7>;
.reg .f64 %fd<7>;
.reg .b64 %rd<10>;

	.shared .align 8 .f64 _ZZ27compute_partial_sums_kernelILi128EEviPKdPdE4lsum;

ld.param.u32 %r4, [_Z27compute_partial_sums_kernelILi128EEviPKdPd_param_0];
ld.param.u64 %rd1, [_Z27compute_partial_sums_kernelILi128EEviPKdPd_param_1];
ld.param.u64 %rd2, [_Z27compute_partial_sums_kernelILi128EEviPKdPd_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r5, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r5, %r2;
setp.ge.s32 %p1, %r3, %r4;
mov.f64 %fd6, 0d0000000000000000;
@%p1 bra $L__BB1_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.s32 %rd4, %r3, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.nc.f64 %fd6, [%rd5];

$L__BB1_2:
setp.ne.s32 %p2, %r2, 0;
@%p2 bra $L__BB1_4;

mov.u64 %rd6, 0;
st.shared.u64 [_ZZ27compute_partial_sums_kernelILi128EEviPKdPdE4lsum], %rd6;

$L__BB1_4:
bar.sync 0;
mov.u32 %r6, _ZZ27compute_partial_sums_kernelILi128EEviPKdPdE4lsum;
atom.shared.add.f64 %fd4, [%r6], %fd6;
bar.sync 0;
@%p2 bra $L__BB1_6;

ld.shared.f64 %fd5, [_ZZ27compute_partial_sums_kernelILi128EEviPKdPdE4lsum];
cvta.to.global.u64 %rd7, %rd2;
mul.wide.u32 %rd8, %r1, 8;
add.s64 %rd9, %rd7, %rd8;
st.global.f64 [%rd9], %fd5;

$L__BB1_6:
ret;

}

.visible .entry _Z24compute_final_sum_kernelILi128EEviidPd(
.param .u32 _Z24compute_final_sum_kernelILi128EEviidPd_param_0,
.param .u32 _Z24compute_final_sum_kernelILi128EEviidPd_param_1,
.param .f64 _Z24compute_final_sum_kernelILi128EEviidPd_param_2,
.param .u64 _Z24compute_final_sum_kernelILi128EEviidPd_param_3
)
.maxntid 128, 1, 1
{
.reg .pred %p<8>;
.reg .b32 %r<21>;
.reg .f64 %fd<31>;
.reg .b64 %rd<15>;

	.shared .align 8 .f64 _ZZ24compute_final_sum_kernelILi128EEviidPdE4lsum;

ld.param.u32 %r11, [_Z24compute_final_sum_kernelILi128EEviidPd_param_0];
ld.param.u32 %r12, [_Z24compute_final_sum_kernelILi128EEviidPd_param_1];
ld.param.f64 %fd8, [_Z24compute_final_sum_kernelILi128EEviidPd_param_2];
ld.param.u64 %rd8, [_Z24compute_final_sum_kernelILi128EEviidPd_param_3];
cvta.to.global.u64 %rd1, %rd8;
mov.u32 %r1, %tid.x;
setp.ge.s32 %p1, %r1, %r12;
mov.f64 %fd30, 0d0000000000000000;
@%p1 bra $L__BB2_7;

not.b32 %r13, %r1;
add.s32 %r2, %r13, %r12;
shr.u32 %r14, %r2, 7;
add.s32 %r15, %r14, 1;
and.b32 %r18, %r15, 3;
setp.eq.s32 %p2, %r18, 0;
mov.f64 %fd30, 0d0000000000000000;
mov.u32 %r19, %r1;
@%p2 bra $L__BB2_4;

mul.wide.s32 %rd9, %r1, 8;
add.s64 %rd13, %rd1, %rd9;
mov.u32 %r19, %r1;

$L__BB2_3:
.pragma "nounroll";
ld.global.f64 %fd13, [%rd13];
add.f64 %fd30, %fd30, %fd13;
add.s32 %r19, %r19, 128;
add.s64 %rd13, %rd13, 1024;
add.s32 %r18, %r18, -1;
setp.ne.s32 %p3, %r18, 0;
@%p3 bra $L__BB2_3;

$L__BB2_4:
setp.lt.u32 %p4, %r2, 384;
@%p4 bra $L__BB2_7;

mul.wide.s32 %rd10, %r19, 8;
add.s64 %rd11, %rd1, %rd10;
add.s64 %rd14, %rd11, 2048;

$L__BB2_6:
ld.global.f64 %fd14, [%rd14+-2048];
add.f64 %fd15, %fd30, %fd14;
ld.global.f64 %fd16, [%rd14+-1024];
add.f64 %fd17, %fd15, %fd16;
ld.global.f64 %fd18, [%rd14];
add.f64 %fd19, %fd17, %fd18;
ld.global.f64 %fd20, [%rd14+1024];
add.f64 %fd30, %fd19, %fd20;
add.s64 %rd14, %rd14, 4096;
add.s32 %r19, %r19, 512;
setp.lt.s32 %p5, %r19, %r12;
@%p5 bra $L__BB2_6;

$L__BB2_7:
setp.ne.s32 %p6, %r1, 0;
@%p6 bra $L__BB2_9;

mov.u64 %rd12, 0;
st.shared.u64 [_ZZ24compute_final_sum_kernelILi128EEviidPdE4lsum], %rd12;

$L__BB2_9:
bar.sync 0;
mov.u32 %r16, _ZZ24compute_final_sum_kernelILi128EEviidPdE4lsum;
atom.shared.add.f64 %fd21, [%r16], %fd30;
bar.sync 0;
@%p6 bra $L__BB2_11;

ld.shared.f64 %fd22, [_ZZ24compute_final_sum_kernelILi128EEviidPdE4lsum];
mul.f64 %fd23, %fd22, %fd8;
cvt.rn.f64.s32 %fd24, %r11;
div.rn.f64 %fd25, %fd23, %fd24;
st.global.f64 [%rd1], %fd25;

$L__BB2_11:
ret;

}

.visible .entry _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd(
.param .u32 _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_0,
.param .u32 _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_1,
.param .align 8 .b8 _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_2[8],
.param .f64 _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_3,
.param .f64 _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_4,
.param .f64 _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_5,
.param .f64 _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_6,
.param .u64 _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_7,
.param .u64 _Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_8
)
.maxntid 256, 1, 1
{
.reg .pred %p<6>;
.reg .f32 %f<3>;
.reg .b32 %r<27>;
.reg .f64 %fd<59>;
.reg .b64 %rd<15>;


ld.param.f64 %fd11, [_Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_2];
ld.param.u32 %r7, [_Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_0];
ld.param.u32 %r8, [_Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_1];
ld.param.f64 %fd12, [_Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_3];
ld.param.f64 %fd57, [_Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_4];
ld.param.f64 %fd14, [_Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_5];
ld.param.f64 %fd15, [_Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_6];
ld.param.u64 %rd7, [_Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_7];
ld.param.u64 %rd8, [_Z21generate_paths_kernelILi256E9PayoffPutEviiT0_ddddPKdPd_param_8];
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 8;
mov.u32 %r11, %tid.x;
add.s32 %r1, %r10, %r11;
setp.ge.s32 %p1, %r1, %r8;
@%p1 bra $L__BB3_7;

mul.f64 %fd16, %fd15, 0dBFE0000000000000;
fma.rn.f64 %fd17, %fd16, %fd15, %fd14;
mul.f64 %fd1, %fd17, %fd12;
sqrt.rn.f64 %fd18, %fd12;
mul.f64 %fd2, %fd18, %fd15;
cvta.to.global.u64 %rd9, %rd8;
mul.wide.s32 %rd10, %r1, 8;
add.s64 %rd14, %rd9, %rd10;
cvta.to.global.u64 %rd11, %rd7;
add.s64 %rd13, %rd11, %rd10;
mov.u32 %r26, 0;
add.s32 %r25, %r7, -1;
bra.uni $L__BB3_2;

$L__BB3_8:
st.global.f64 [%rd14], %fd57;
add.s32 %r26, %r26, 1;
mul.wide.s32 %rd12, %r8, 8;
add.s64 %rd14, %rd14, %rd12;
add.s64 %rd13, %rd13, %rd12;

$L__BB3_2:
ld.global.nc.f64 %fd19, [%rd13];
fma.rn.f64 %fd5, %fd2, %fd19, %fd1;
mov.f64 %fd20, 0d4338000000000000;
mov.f64 %fd21, 0d3FF71547652B82FE;
fma.rn.f64 %fd22, %fd5, %fd21, %fd20;
{
.reg .b32 %temp; 
mov.b64 {%r3, %temp}, %fd22;
}
mov.f64 %fd23, 0dC338000000000000;
add.rn.f64 %fd24, %fd22, %fd23;
mov.f64 %fd25, 0dBFE62E42FEFA39EF;
fma.rn.f64 %fd26, %fd24, %fd25, %fd5;
mov.f64 %fd27, 0dBC7ABC9E3B39803F;
fma.rn.f64 %fd28, %fd24, %fd27, %fd26;
mov.f64 %fd29, 0d3E928AF3FCA213EA;
mov.f64 %fd30, 0d3E5ADE1569CE2BDF;
fma.rn.f64 %fd31, %fd30, %fd28, %fd29;
mov.f64 %fd32, 0d3EC71DEE62401315;
fma.rn.f64 %fd33, %fd31, %fd28, %fd32;
mov.f64 %fd34, 0d3EFA01997C89EB71;
fma.rn.f64 %fd35, %fd33, %fd28, %fd34;
mov.f64 %fd36, 0d3F2A01A014761F65;
fma.rn.f64 %fd37, %fd35, %fd28, %fd36;
mov.f64 %fd38, 0d3F56C16C1852B7AF;
fma.rn.f64 %fd39, %fd37, %fd28, %fd38;
mov.f64 %fd40, 0d3F81111111122322;
fma.rn.f64 %fd41, %fd39, %fd28, %fd40;
mov.f64 %fd42, 0d3FA55555555502A1;
fma.rn.f64 %fd43, %fd41, %fd28, %fd42;
mov.f64 %fd44, 0d3FC5555555555511;
fma.rn.f64 %fd45, %fd43, %fd28, %fd44;
mov.f64 %fd46, 0d3FE000000000000B;
fma.rn.f64 %fd47, %fd45, %fd28, %fd46;
mov.f64 %fd48, 0d3FF0000000000000;
fma.rn.f64 %fd49, %fd47, %fd28, %fd48;
fma.rn.f64 %fd50, %fd49, %fd28, %fd48;
{
.reg .b32 %temp; 
mov.b64 {%r4, %temp}, %fd50;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r5}, %fd50;
}
shl.b32 %r13, %r3, 20;
add.s32 %r14, %r5, %r13;
mov.b64 %fd58, {%r4, %r14};
{
.reg .b32 %temp; 
mov.b64 {%temp, %r15}, %fd5;
}
mov.b32 %f2, %r15;
abs.ftz.f32 %f1, %f2;
setp.lt.ftz.f32 %p2, %f1, 0f4086232B;
@%p2 bra $L__BB3_5;

setp.lt.f64 %p3, %fd5, 0d0000000000000000;
add.f64 %fd51, %fd5, 0d7FF0000000000000;
selp.f64 %fd58, 0d0000000000000000, %fd51, %p3;
setp.geu.ftz.f32 %p4, %f1, 0f40874800;
@%p4 bra $L__BB3_5;

shr.u32 %r16, %r3, 31;
add.s32 %r17, %r3, %r16;
shr.s32 %r18, %r17, 1;
shl.b32 %r19, %r18, 20;
add.s32 %r20, %r5, %r19;
mov.b64 %fd52, {%r4, %r20};
sub.s32 %r21, %r3, %r18;
shl.b32 %r22, %r21, 20;
add.s32 %r23, %r22, 1072693248;
mov.u32 %r24, 0;
mov.b64 %fd53, {%r24, %r23};
mul.f64 %fd58, %fd52, %fd53;

$L__BB3_5:
setp.lt.s32 %p5, %r26, %r25;
mul.f64 %fd57, %fd57, %fd58;
@%p5 bra $L__BB3_8;

sub.f64 %fd54, %fd11, %fd57;
mov.f64 %fd55, 0d0000000000000000;
max.f64 %fd56, %fd54, %fd55;
st.global.f64 [%rd14], %fd56;

$L__BB3_7:
ret;

}

.visible .entry _Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd(
.param .u32 _Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_0,
.param .u32 _Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_1,
.param .align 8 .b8 _Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_2[8],
.param .u64 _Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_3,
.param .u64 _Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_4,
.param .u64 _Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_5
)
.maxntid 256, 1, 1
.minnctapersm 4
{
.reg .pred %p<41>;
.reg .b32 %r<121>;
.reg .f64 %fd<545>;
.reg .b64 %rd<15>;

	.shared .align 4 .b8 _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE10scan_input[1024];

	.shared .align 4 .b8 _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE11scan_output[1028];

	.shared .align 16 .b8 _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE5lsums[32];

	.shared .align 4 .u32 _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE4lsum;

	.shared .align 8 .b8 _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds[96];

ld.param.f64 %fd165, [_Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_2];
ld.param.u32 %r21, [_Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_0];
ld.param.u32 %r22, [_Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_1];
ld.param.u64 %rd1, [_Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_3];
ld.param.u64 %rd2, [_Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_4];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 11;
shl.b32 %r23, %r1, 3;
mov.u32 %r24, _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds;
add.s32 %r2, %r24, %r23;
@%p1 bra $L__BB4_2;

mov.u64 %rd4, 0;
st.shared.u64 [%r2], %rd4;

$L__BB4_2:
bar.sync 0;
setp.ge.s32 %p2, %r1, %r21;
mov.u32 %r118, 0;
mov.f64 %fd470, 0d0000000000000000;
mov.f64 %fd471, %fd470;
mov.f64 %fd472, %fd470;
mov.f64 %fd473, %fd470;
@%p2 bra $L__BB4_16;

cvta.to.global.u64 %rd5, %rd1;
mov.u32 %r112, %r1;
mov.u32 %r117, %r118;

$L__BB4_4:
setp.ne.s32 %p3, %r1, 0;
mov.u32 %r29, %ctaid.x;
mad.lo.s32 %r30, %r29, %r21, %r112;
mul.wide.s32 %rd6, %r30, 8;
add.s64 %rd7, %rd5, %rd6;
ld.global.nc.f64 %fd6, [%rd7];
setp.gt.f64 %p4, %fd165, %fd6;
selp.u32 %r6, 1, 0, %p4;
shl.b32 %r31, %r1, 2;
mov.u32 %r32, _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE10scan_input;
add.s32 %r33, %r32, %r31;
st.shared.u32 [%r33], %r6;
bar.sync 0;
@%p3 bra $L__BB4_7;

mov.u32 %r115, 0;
st.shared.u32 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE11scan_output], %r115;
mov.u32 %r116, 1;

$L__BB4_6:
shl.b32 %r36, %r116, 2;
add.s32 %r38, %r32, %r36;
ld.shared.u32 %r39, [%r38+-4];
add.s32 %r40, %r39, %r115;
mov.u32 %r41, _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE11scan_output;
add.s32 %r42, %r41, %r36;
st.shared.u32 [%r42], %r40;
ld.shared.u32 %r43, [%r38];
add.s32 %r44, %r43, %r40;
st.shared.u32 [%r42+4], %r44;
ld.shared.u32 %r45, [%r38+4];
add.s32 %r46, %r45, %r44;
st.shared.u32 [%r42+8], %r46;
ld.shared.u32 %r47, [%r38+8];
add.s32 %r48, %r47, %r46;
st.shared.u32 [%r42+12], %r48;
ld.shared.u32 %r49, [%r38+12];
add.s32 %r50, %r49, %r48;
st.shared.u32 [%r42+16], %r50;
ld.shared.u32 %r51, [%r38+16];
add.s32 %r52, %r51, %r50;
st.shared.u32 [%r42+20], %r52;
ld.shared.u32 %r53, [%r38+20];
add.s32 %r54, %r53, %r52;
st.shared.u32 [%r42+24], %r54;
ld.shared.u32 %r55, [%r38+24];
add.s32 %r56, %r55, %r54;
st.shared.u32 [%r42+28], %r56;
ld.shared.u32 %r57, [%r38+28];
add.s32 %r58, %r57, %r56;
st.shared.u32 [%r42+32], %r58;
ld.shared.u32 %r59, [%r38+32];
add.s32 %r60, %r59, %r58;
st.shared.u32 [%r42+36], %r60;
ld.shared.u32 %r61, [%r38+36];
add.s32 %r62, %r61, %r60;
st.shared.u32 [%r42+40], %r62;
ld.shared.u32 %r63, [%r38+40];
add.s32 %r64, %r63, %r62;
st.shared.u32 [%r42+44], %r64;
ld.shared.u32 %r65, [%r38+44];
add.s32 %r66, %r65, %r64;
st.shared.u32 [%r42+48], %r66;
ld.shared.u32 %r67, [%r38+48];
add.s32 %r68, %r67, %r66;
st.shared.u32 [%r42+52], %r68;
ld.shared.u32 %r69, [%r38+52];
add.s32 %r70, %r69, %r68;
st.shared.u32 [%r42+56], %r70;
ld.shared.u32 %r71, [%r38+56];
add.s32 %r115, %r71, %r70;
st.shared.u32 [%r42+60], %r115;
add.s32 %r116, %r116, 16;
setp.ne.s32 %p5, %r116, 257;
@%p5 bra $L__BB4_6;

$L__BB4_7:
bar.sync 0;
setp.gt.s32 %p6, %r117, 2;
@%p6 bra $L__BB4_11;

ld.shared.u32 %r11, [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE11scan_output+1024];
mov.u32 %r72, _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE11scan_output;
setp.leu.f64 %p7, %fd165, %fd6;
mov.u32 %r73, %tid.x;
shl.b32 %r74, %r73, 2;
add.s32 %r75, %r72, %r74;
ld.shared.u32 %r76, [%r75];
add.s32 %r12, %r76, %r117;
setp.gt.s32 %p8, %r12, 2;
or.pred %p9, %p7, %p8;
@%p9 bra $L__BB4_10;

shl.b32 %r77, %r12, 3;
add.s32 %r79, %r24, %r77;
st.shared.f64 [%r79], %fd6;

$L__BB4_10:
bar.sync 0;
add.s32 %r117, %r11, %r117;

$L__BB4_11:
mov.u32 %r80, %tid.x;
setp.ne.s32 %p10, %r80, 0;
@%p10 bra $L__BB4_13;

mov.u32 %r81, 0;
st.shared.u32 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE4lsum], %r81;

$L__BB4_13:
bar.sync 0;
mov.u32 %r82, _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE4lsum;
atom.shared.or.b32 %r83, [%r82], %r6;
bar.sync 0;
ld.shared.u32 %r84, [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE4lsum];
setp.eq.s32 %p11, %r84, 0;
@%p11 bra $L__BB4_15;

add.s32 %r118, %r118, %r6;
selp.f64 %fd174, %fd6, 0d0000000000000000, %p4;
mul.f64 %fd175, %fd6, %fd6;
selp.f64 %fd176, %fd175, 0d0000000000000000, %p4;
add.f64 %fd473, %fd473, %fd174;
add.f64 %fd472, %fd472, %fd176;
fma.rn.f64 %fd471, %fd176, %fd174, %fd471;
fma.rn.f64 %fd470, %fd176, %fd176, %fd470;

$L__BB4_15:
add.s32 %r112, %r112, 256;
setp.lt.s32 %p13, %r112, %r21;
@%p13 bra $L__BB4_4;

$L__BB4_16:
mov.u32 %r85, %tid.x;
setp.ne.s32 %p14, %r85, 0;
@%p14 bra $L__BB4_18;

mov.u32 %r86, 0;
st.shared.u32 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE4lsum], %r86;

$L__BB4_18:
setp.eq.s32 %p15, %r85, 0;
bar.sync 0;
mov.u32 %r88, _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE4lsum;
atom.shared.add.u32 %r89, [%r88], %r118;
bar.sync 0;
ld.shared.u32 %r90, [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE4lsum];
setp.lt.s32 %p16, %r90, %r22;
and.pred %p17, %p15, %p16;
@%p17 bra $L__BB4_56;
bra.uni $L__BB4_19;

$L__BB4_56:
mov.u32 %r107, %ctaid.x;
cvta.to.global.u64 %rd11, %rd2;
mul.wide.u32 %rd12, %r107, 4;
add.s64 %rd13, %rd11, %rd12;
mov.u32 %r108, 1;
st.global.u32 [%rd13], %r108;
bra.uni $L__BB4_57;

$L__BB4_19:
@%p14 bra $L__BB4_21;

mov.f64 %fd177, 0d0000000000000000;
st.shared.v2.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE5lsums], {%fd177, %fd177};
st.shared.v2.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE5lsums+16], {%fd177, %fd177};

$L__BB4_21:
bar.sync 0;
mov.u32 %r93, _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE5lsums;
atom.shared.add.f64 %fd178, [%r93], %fd473;
add.s32 %r94, %r93, 8;
atom.shared.add.f64 %fd179, [%r94], %fd472;
add.s32 %r95, %r93, 16;
atom.shared.add.f64 %fd180, [%r95], %fd471;
add.s32 %r96, %r93, 24;
atom.shared.add.f64 %fd181, [%r96], %fd470;
bar.sync 0;
@%p14 bra $L__BB4_54;

ld.shared.u32 %r97, [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE4lsum];
ld.shared.f64 %fd183, [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+8];
ld.shared.f64 %fd19, [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+16];
ld.shared.f64 %fd184, [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds];
mul.f64 %fd185, %fd184, %fd184;
ld.shared.v2.f64 {%fd186, %fd187}, [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE5lsums];
sub.f64 %fd190, %fd186, %fd184;
sub.f64 %fd191, %fd187, %fd185;
ld.shared.v2.f64 {%fd192, %fd193}, [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE5lsums+16];
mul.f64 %fd196, %fd184, %fd185;
sub.f64 %fd197, %fd192, %fd196;
mul.f64 %fd198, %fd185, %fd185;
sub.f64 %fd20, %fd193, %fd198;
cvt.rn.f64.s32 %fd21, %r97;
add.f64 %fd199, %fd21, 0dBFF0000000000000;
mov.f64 %fd200, 0d3FF0000000000000;
sqrt.rn.f64 %fd22, %fd21;
neg.f64 %fd201, %fd199;
add.f64 %fd202, %fd22, 0d3FF0000000000000;
div.rn.f64 %fd483, %fd201, %fd202;
mul.f64 %fd203, %fd483, %fd483;
fma.rn.f64 %fd204, %fd483, %fd483, %fd203;
add.f64 %fd205, %fd199, %fd203;
div.rn.f64 %fd206, %fd204, %fd205;
rcp.rn.f64 %fd479, %fd483;
sub.f64 %fd207, %fd200, %fd206;
mul.f64 %fd208, %fd479, %fd206;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds], %fd22;
mul.f64 %fd209, %fd184, %fd207;
mul.f64 %fd210, %fd190, %fd208;
sub.f64 %fd25, %fd209, %fd210;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+8], %fd25;
mul.f64 %fd211, %fd185, %fd207;
mul.f64 %fd212, %fd191, %fd208;
sub.f64 %fd26, %fd211, %fd212;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+16], %fd26;
mul.f64 %fd213, %fd479, %fd208;
mul.f64 %fd214, %fd190, %fd213;
fma.rn.f64 %fd27, %fd184, %fd208, %fd214;
mul.f64 %fd215, %fd191, %fd213;
fma.rn.f64 %fd28, %fd185, %fd208, %fd215;
mul.f64 %fd29, %fd183, %fd183;
sub.f64 %fd30, %fd190, %fd183;
sub.f64 %fd31, %fd191, %fd29;
mul.f64 %fd216, %fd183, %fd29;
sub.f64 %fd32, %fd197, %fd216;
sub.f64 %fd33, %fd183, %fd27;
add.f64 %fd217, %fd27, %fd27;
mul.f64 %fd218, %fd30, %fd217;
sub.f64 %fd219, %fd31, %fd218;
add.f64 %fd220, %fd21, 0dC000000000000000;
mul.f64 %fd34, %fd220, %fd27;
fma.rn.f64 %fd35, %fd27, %fd34, %fd219;
abs.f64 %fd221, %fd35;
setp.lt.f64 %p20, %fd221, 0d3C9CD2B297D889BC;
mov.f64 %fd182, 0d0000000000000000;
mov.f64 %fd481, %fd182;
@%p20 bra $L__BB4_27;

fma.rn.f64 %fd222, %fd33, %fd33, %fd35;
sqrt.rn.f64 %fd36, %fd222;
setp.gtu.f64 %p21, %fd33, 0d0000000000000000;
@%p21 bra $L__BB4_25;
bra.uni $L__BB4_24;

$L__BB4_25:
neg.f64 %fd223, %fd35;
add.f64 %fd224, %fd33, %fd36;
div.rn.f64 %fd483, %fd223, %fd224;
bra.uni $L__BB4_26;

$L__BB4_24:
sub.f64 %fd483, %fd33, %fd36;

$L__BB4_26:
mul.f64 %fd225, %fd483, %fd483;
fma.rn.f64 %fd226, %fd483, %fd483, %fd225;
add.f64 %fd227, %fd35, %fd225;
div.rn.f64 %fd481, %fd226, %fd227;
rcp.rn.f64 %fd479, %fd483;

$L__BB4_27:
mul.f64 %fd229, %fd31, %fd27;
sub.f64 %fd230, %fd32, %fd229;
mul.f64 %fd231, %fd30, %fd28;
sub.f64 %fd232, %fd230, %fd231;
fma.rn.f64 %fd233, %fd28, %fd34, %fd232;
mul.f64 %fd234, %fd479, %fd481;
mul.f64 %fd235, %fd233, %fd234;
sub.f64 %fd236, %fd29, %fd28;
mul.f64 %fd237, %fd479, %fd235;
fma.rn.f64 %fd238, %fd236, %fd234, %fd237;
mul.f64 %fd239, %fd27, %fd238;
sub.f64 %fd240, %fd239, %fd28;
sub.f64 %fd242, %fd200, %fd481;
mul.f64 %fd243, %fd33, %fd242;
mul.f64 %fd244, %fd35, %fd234;
sub.f64 %fd45, %fd243, %fd244;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+24], %fd45;
mul.f64 %fd245, %fd236, %fd242;
sub.f64 %fd46, %fd245, %fd235;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+32], %fd46;
mul.f64 %fd246, %fd19, %fd19;
sub.f64 %fd247, %fd31, %fd246;
mul.f64 %fd248, %fd19, %fd246;
sub.f64 %fd249, %fd32, %fd248;
mul.f64 %fd250, %fd246, %fd246;
mul.f64 %fd251, %fd29, %fd29;
sub.f64 %fd252, %fd20, %fd251;
sub.f64 %fd253, %fd252, %fd250;
mul.f64 %fd254, %fd19, %fd238;
sub.f64 %fd255, %fd246, %fd254;
add.f64 %fd47, %fd255, %fd240;
add.f64 %fd256, %fd238, %fd238;
mul.f64 %fd257, %fd249, %fd256;
sub.f64 %fd258, %fd253, %fd257;
add.f64 %fd259, %fd240, %fd240;
fma.rn.f64 %fd260, %fd238, %fd238, %fd259;
fma.rn.f64 %fd261, %fd247, %fd260, %fd258;
mul.f64 %fd262, %fd256, %fd240;
sub.f64 %fd263, %fd30, %fd19;
mul.f64 %fd264, %fd263, %fd262;
sub.f64 %fd265, %fd261, %fd264;
add.f64 %fd266, %fd21, 0dC008000000000000;
mul.f64 %fd267, %fd266, %fd240;
fma.rn.f64 %fd48, %fd240, %fd267, %fd265;
abs.f64 %fd268, %fd48;
setp.lt.f64 %p22, %fd268, 0d3D719799812DEA11;
mov.f64 %fd484, %fd182;
@%p22 bra $L__BB4_32;

fma.rn.f64 %fd269, %fd47, %fd47, %fd48;
sqrt.rn.f64 %fd49, %fd269;
setp.gtu.f64 %p23, %fd47, 0d0000000000000000;
@%p23 bra $L__BB4_30;
bra.uni $L__BB4_29;

$L__BB4_30:
neg.f64 %fd270, %fd48;
add.f64 %fd271, %fd47, %fd49;
div.rn.f64 %fd483, %fd270, %fd271;
bra.uni $L__BB4_31;

$L__BB4_29:
sub.f64 %fd483, %fd47, %fd49;

$L__BB4_31:
mul.f64 %fd272, %fd483, %fd483;
fma.rn.f64 %fd273, %fd483, %fd483, %fd272;
add.f64 %fd274, %fd48, %fd272;
div.rn.f64 %fd484, %fd273, %fd274;

$L__BB4_32:
sub.f64 %fd284, %fd200, %fd484;
mul.f64 %fd285, %fd47, %fd284;
div.rn.f64 %fd286, %fd484, %fd483;
mul.f64 %fd287, %fd48, %fd286;
sub.f64 %fd56, %fd285, %fd287;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+40], %fd56;
mul.f64 %fd517, %fd22, %fd22;
mul.f64 %fd288, %fd45, %fd45;
fma.rn.f64 %fd506, %fd25, %fd25, %fd288;
mul.f64 %fd289, %fd45, %fd46;
fma.rn.f64 %fd487, %fd25, %fd26, %fd289;
mul.f64 %fd290, %fd46, %fd46;
fma.rn.f64 %fd291, %fd26, %fd26, %fd290;
fma.rn.f64 %fd507, %fd56, %fd56, %fd291;
mul.f64 %fd485, %fd22, %fd25;
mul.f64 %fd292, %fd485, %fd485;
mul.f64 %fd486, %fd22, %fd26;
fma.rn.f64 %fd293, %fd486, %fd486, %fd292;
fma.rn.f64 %fd294, %fd487, %fd487, %fd293;
add.f64 %fd295, %fd294, %fd294;
sqrt.rn.f64 %fd296, %fd295;
setp.ltu.f64 %p24, %fd296, 0d3D719799812DEA11;
mov.f64 %fd508, %fd200;
mov.f64 %fd509, %fd182;
mov.f64 %fd510, %fd182;
mov.f64 %fd511, %fd182;
mov.f64 %fd512, %fd200;
mov.f64 %fd513, %fd182;
mov.f64 %fd514, %fd182;
mov.f64 %fd515, %fd182;
mov.f64 %fd516, %fd200;
@%p24 bra $L__BB4_41;

mov.u32 %r120, 0;
mov.f64 %fd516, %fd200;
mov.f64 %fd515, %fd182;
mov.f64 %fd514, %fd182;
mov.f64 %fd513, %fd182;
mov.f64 %fd512, %fd200;
mov.f64 %fd511, %fd182;
mov.f64 %fd510, %fd182;
mov.f64 %fd509, %fd182;
mov.f64 %fd508, %fd200;

$L__BB4_34:
setp.eq.f64 %p25, %fd485, 0d0000000000000000;
mov.f64 %fd500, %fd200;
mov.f64 %fd501, %fd182;
@%p25 bra $L__BB4_36;

sub.f64 %fd308, %fd506, %fd517;
add.f64 %fd309, %fd485, %fd485;
div.rn.f64 %fd310, %fd308, %fd309;
setp.lt.f64 %p26, %fd310, 0d0000000000000000;
selp.f64 %fd311, 0dBFF0000000000000, 0d3FF0000000000000, %p26;
fma.rn.f64 %fd312, %fd310, %fd310, 0d3FF0000000000000;
sqrt.rn.f64 %fd313, %fd312;
fma.rn.f64 %fd314, %fd310, %fd311, %fd313;
div.rn.f64 %fd315, %fd311, %fd314;
fma.rn.f64 %fd316, %fd315, %fd315, 0d3FF0000000000000;
sqrt.rn.f64 %fd317, %fd316;
rcp.rn.f64 %fd500, %fd317;
mul.f64 %fd501, %fd315, %fd500;

$L__BB4_36:
mul.f64 %fd320, %fd485, %fd501;
mul.f64 %fd321, %fd517, %fd500;
sub.f64 %fd322, %fd321, %fd320;
mul.f64 %fd323, %fd485, %fd500;
fma.rn.f64 %fd324, %fd517, %fd501, %fd323;
mul.f64 %fd325, %fd506, %fd501;
sub.f64 %fd326, %fd323, %fd325;
fma.rn.f64 %fd327, %fd506, %fd500, %fd320;
mul.f64 %fd328, %fd500, %fd322;
mul.f64 %fd329, %fd501, %fd326;
sub.f64 %fd82, %fd328, %fd329;
mul.f64 %fd330, %fd500, %fd324;
mul.f64 %fd331, %fd501, %fd327;
sub.f64 %fd83, %fd330, %fd331;
mul.f64 %fd332, %fd500, %fd327;
fma.rn.f64 %fd84, %fd501, %fd324, %fd332;
mul.f64 %fd333, %fd487, %fd501;
mul.f64 %fd334, %fd486, %fd500;
sub.f64 %fd85, %fd334, %fd333;
mul.f64 %fd335, %fd486, %fd501;
fma.rn.f64 %fd86, %fd487, %fd500, %fd335;
mul.f64 %fd336, %fd509, %fd501;
mul.f64 %fd337, %fd508, %fd500;
sub.f64 %fd87, %fd337, %fd336;
mul.f64 %fd338, %fd508, %fd501;
fma.rn.f64 %fd88, %fd509, %fd500, %fd338;
mul.f64 %fd339, %fd512, %fd501;
mul.f64 %fd340, %fd511, %fd500;
sub.f64 %fd89, %fd340, %fd339;
mul.f64 %fd341, %fd511, %fd501;
fma.rn.f64 %fd90, %fd512, %fd500, %fd341;
mul.f64 %fd342, %fd515, %fd501;
mul.f64 %fd343, %fd514, %fd500;
sub.f64 %fd91, %fd343, %fd342;
mul.f64 %fd344, %fd514, %fd501;
fma.rn.f64 %fd92, %fd515, %fd500, %fd344;
setp.eq.f64 %p27, %fd85, 0d0000000000000000;
mov.f64 %fd502, %fd200;
mov.f64 %fd503, %fd182;
@%p27 bra $L__BB4_38;

sub.f64 %fd345, %fd507, %fd82;
add.f64 %fd346, %fd85, %fd85;
div.rn.f64 %fd347, %fd345, %fd346;
setp.lt.f64 %p28, %fd347, 0d0000000000000000;
selp.f64 %fd348, 0dBFF0000000000000, 0d3FF0000000000000, %p28;
fma.rn.f64 %fd349, %fd347, %fd347, 0d3FF0000000000000;
sqrt.rn.f64 %fd350, %fd349;
fma.rn.f64 %fd351, %fd347, %fd348, %fd350;
div.rn.f64 %fd352, %fd348, %fd351;
fma.rn.f64 %fd353, %fd352, %fd352, 0d3FF0000000000000;
sqrt.rn.f64 %fd354, %fd353;
rcp.rn.f64 %fd502, %fd354;
mul.f64 %fd503, %fd352, %fd502;

$L__BB4_38:
mul.f64 %fd357, %fd85, %fd503;
mul.f64 %fd358, %fd82, %fd502;
sub.f64 %fd359, %fd358, %fd357;
mul.f64 %fd360, %fd86, %fd503;
mul.f64 %fd361, %fd83, %fd502;
sub.f64 %fd97, %fd361, %fd360;
mul.f64 %fd362, %fd85, %fd502;
fma.rn.f64 %fd363, %fd82, %fd503, %fd362;
mul.f64 %fd364, %fd507, %fd503;
sub.f64 %fd365, %fd362, %fd364;
fma.rn.f64 %fd366, %fd507, %fd502, %fd357;
mul.f64 %fd367, %fd502, %fd359;
mul.f64 %fd368, %fd503, %fd365;
sub.f64 %fd517, %fd367, %fd368;
mul.f64 %fd369, %fd83, %fd503;
fma.rn.f64 %fd99, %fd86, %fd502, %fd369;
mul.f64 %fd370, %fd502, %fd363;
mul.f64 %fd371, %fd503, %fd366;
sub.f64 %fd100, %fd370, %fd371;
mul.f64 %fd372, %fd502, %fd366;
fma.rn.f64 %fd101, %fd503, %fd363, %fd372;
mul.f64 %fd373, %fd510, %fd503;
mul.f64 %fd374, %fd87, %fd502;
sub.f64 %fd508, %fd374, %fd373;
mul.f64 %fd375, %fd87, %fd503;
fma.rn.f64 %fd103, %fd510, %fd502, %fd375;
mul.f64 %fd376, %fd513, %fd503;
mul.f64 %fd377, %fd89, %fd502;
sub.f64 %fd511, %fd377, %fd376;
mul.f64 %fd378, %fd89, %fd503;
fma.rn.f64 %fd105, %fd513, %fd502, %fd378;
mul.f64 %fd379, %fd516, %fd503;
mul.f64 %fd380, %fd91, %fd502;
sub.f64 %fd514, %fd380, %fd379;
mul.f64 %fd381, %fd91, %fd503;
fma.rn.f64 %fd107, %fd516, %fd502, %fd381;
setp.eq.f64 %p29, %fd99, 0d0000000000000000;
mov.f64 %fd504, %fd200;
mov.f64 %fd505, %fd182;
@%p29 bra $L__BB4_40;

sub.f64 %fd382, %fd101, %fd84;
add.f64 %fd383, %fd99, %fd99;
div.rn.f64 %fd384, %fd382, %fd383;
setp.lt.f64 %p30, %fd384, 0d0000000000000000;
selp.f64 %fd385, 0dBFF0000000000000, 0d3FF0000000000000, %p30;
fma.rn.f64 %fd386, %fd384, %fd384, 0d3FF0000000000000;
sqrt.rn.f64 %fd387, %fd386;
fma.rn.f64 %fd388, %fd384, %fd385, %fd387;
div.rn.f64 %fd389, %fd385, %fd388;
fma.rn.f64 %fd390, %fd389, %fd389, 0d3FF0000000000000;
sqrt.rn.f64 %fd391, %fd390;
rcp.rn.f64 %fd504, %fd391;
mul.f64 %fd505, %fd389, %fd504;

$L__BB4_40:
mul.f64 %fd392, %fd97, %fd505;
fma.rn.f64 %fd486, %fd100, %fd504, %fd392;
mul.f64 %fd393, %fd99, %fd505;
mul.f64 %fd394, %fd84, %fd504;
sub.f64 %fd395, %fd394, %fd393;
mul.f64 %fd396, %fd99, %fd504;
fma.rn.f64 %fd397, %fd84, %fd505, %fd396;
mul.f64 %fd398, %fd101, %fd505;
sub.f64 %fd399, %fd396, %fd398;
fma.rn.f64 %fd400, %fd101, %fd504, %fd393;
mul.f64 %fd401, %fd100, %fd505;
mul.f64 %fd402, %fd97, %fd504;
sub.f64 %fd485, %fd402, %fd401;
mul.f64 %fd403, %fd504, %fd395;
mul.f64 %fd404, %fd505, %fd399;
sub.f64 %fd506, %fd403, %fd404;
mul.f64 %fd405, %fd504, %fd397;
mul.f64 %fd406, %fd505, %fd400;
sub.f64 %fd487, %fd405, %fd406;
mul.f64 %fd407, %fd504, %fd400;
fma.rn.f64 %fd507, %fd505, %fd397, %fd407;
mul.f64 %fd408, %fd103, %fd505;
mul.f64 %fd409, %fd88, %fd504;
sub.f64 %fd509, %fd409, %fd408;
mul.f64 %fd410, %fd88, %fd505;
fma.rn.f64 %fd510, %fd103, %fd504, %fd410;
mul.f64 %fd411, %fd105, %fd505;
mul.f64 %fd412, %fd90, %fd504;
sub.f64 %fd512, %fd412, %fd411;
mul.f64 %fd413, %fd90, %fd505;
fma.rn.f64 %fd513, %fd105, %fd504, %fd413;
mul.f64 %fd414, %fd107, %fd505;
mul.f64 %fd415, %fd92, %fd504;
sub.f64 %fd515, %fd415, %fd414;
mul.f64 %fd416, %fd92, %fd505;
fma.rn.f64 %fd516, %fd107, %fd504, %fd416;
mul.f64 %fd417, %fd485, %fd485;
fma.rn.f64 %fd418, %fd486, %fd486, %fd417;
fma.rn.f64 %fd419, %fd487, %fd487, %fd418;
add.f64 %fd420, %fd419, %fd419;
sqrt.rn.f64 %fd421, %fd420;
setp.ge.f64 %p31, %fd421, 0d3D719799812DEA11;
add.s32 %r120, %r120, 1;
setp.lt.u32 %p32, %r120, 16;
and.pred %p33, %p32, %p31;
@%p33 bra $L__BB4_34;

$L__BB4_41:
setp.geu.f64 %p34, %fd517, %fd506;
mov.f64 %fd518, %fd506;
mov.f64 %fd519, %fd508;
mov.f64 %fd521, %fd511;
mov.f64 %fd523, %fd514;
@%p34 bra $L__BB4_43;

mov.f64 %fd518, %fd517;
mov.f64 %fd519, %fd509;
mov.f64 %fd509, %fd508;
mov.f64 %fd521, %fd512;
mov.f64 %fd512, %fd511;
mov.f64 %fd523, %fd515;
mov.f64 %fd515, %fd514;
mov.f64 %fd517, %fd506;

$L__BB4_43:
setp.geu.f64 %p35, %fd517, %fd507;
mov.f64 %fd535, %fd507;
mov.f64 %fd527, %fd519;
mov.f64 %fd529, %fd521;
mov.f64 %fd531, %fd523;
@%p35 bra $L__BB4_45;

mov.f64 %fd535, %fd517;
mov.f64 %fd527, %fd510;
mov.f64 %fd510, %fd519;
mov.f64 %fd529, %fd513;
mov.f64 %fd513, %fd521;
mov.f64 %fd531, %fd516;
mov.f64 %fd516, %fd523;
mov.f64 %fd517, %fd507;

$L__BB4_45:
setp.geu.f64 %p36, %fd518, %fd535;
mov.f64 %fd534, %fd518;
mov.f64 %fd536, %fd509;
mov.f64 %fd538, %fd512;
mov.f64 %fd540, %fd515;
@%p36 bra $L__BB4_47;

mov.f64 %fd534, %fd535;
mov.f64 %fd535, %fd518;
mov.f64 %fd536, %fd510;
mov.f64 %fd510, %fd509;
mov.f64 %fd538, %fd513;
mov.f64 %fd513, %fd512;
mov.f64 %fd540, %fd516;
mov.f64 %fd516, %fd515;

$L__BB4_47:
abs.f64 %fd423, %fd517;
setp.lt.f64 %p37, %fd423, 0d3D719799812DEA11;
mov.f64 %fd544, 0d0000000000000000;
mov.f64 %fd542, %fd544;
@%p37 bra $L__BB4_49;

rcp.rn.f64 %fd542, %fd517;

$L__BB4_49:
abs.f64 %fd425, %fd534;
setp.lt.f64 %p38, %fd425, 0d3D719799812DEA11;
mov.f64 %fd543, %fd544;
@%p38 bra $L__BB4_51;

rcp.rn.f64 %fd543, %fd534;

$L__BB4_51:
abs.f64 %fd427, %fd535;
setp.lt.f64 %p39, %fd427, 0d3D719799812DEA11;
@%p39 bra $L__BB4_53;

rcp.rn.f64 %fd544, %fd535;

$L__BB4_53:
mul.f64 %fd428, %fd527, %fd542;
mul.f64 %fd429, %fd536, %fd543;
mul.f64 %fd430, %fd536, %fd429;
fma.rn.f64 %fd431, %fd527, %fd428, %fd430;
mul.f64 %fd432, %fd510, %fd544;
fma.rn.f64 %fd433, %fd510, %fd432, %fd431;
mul.f64 %fd434, %fd538, %fd429;
fma.rn.f64 %fd435, %fd529, %fd428, %fd434;
fma.rn.f64 %fd436, %fd513, %fd432, %fd435;
mul.f64 %fd437, %fd540, %fd429;
fma.rn.f64 %fd438, %fd531, %fd428, %fd437;
fma.rn.f64 %fd439, %fd516, %fd432, %fd438;
mul.f64 %fd440, %fd529, %fd542;
mul.f64 %fd441, %fd538, %fd543;
mul.f64 %fd442, %fd538, %fd441;
fma.rn.f64 %fd443, %fd529, %fd440, %fd442;
mul.f64 %fd444, %fd513, %fd544;
fma.rn.f64 %fd445, %fd513, %fd444, %fd443;
mul.f64 %fd446, %fd540, %fd441;
fma.rn.f64 %fd447, %fd531, %fd440, %fd446;
fma.rn.f64 %fd448, %fd516, %fd444, %fd447;
mul.f64 %fd449, %fd531, %fd542;
mul.f64 %fd450, %fd540, %fd543;
mul.f64 %fd451, %fd540, %fd450;
fma.rn.f64 %fd452, %fd531, %fd449, %fd451;
mul.f64 %fd453, %fd516, %fd544;
fma.rn.f64 %fd454, %fd516, %fd453, %fd452;
mul.f64 %fd455, %fd25, %fd436;
fma.rn.f64 %fd456, %fd22, %fd433, %fd455;
fma.rn.f64 %fd457, %fd26, %fd439, %fd456;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+48], %fd457;
mul.f64 %fd458, %fd46, %fd439;
fma.rn.f64 %fd459, %fd45, %fd436, %fd458;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+56], %fd459;
mul.f64 %fd460, %fd56, %fd439;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+64], %fd460;
mul.f64 %fd461, %fd46, %fd448;
fma.rn.f64 %fd462, %fd45, %fd445, %fd461;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+72], %fd462;
mul.f64 %fd463, %fd56, %fd448;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+80], %fd463;
mul.f64 %fd464, %fd56, %fd454;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds+88], %fd464;

$L__BB4_54:
mov.u32 %r109, %tid.x;
setp.gt.u32 %p40, %r109, 11;
bar.sync 0;
@%p40 bra $L__BB4_57;

ld.param.u64 %rd14, [_Z18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPd_param_5];
mov.u32 %r111, %tid.x;
mov.u32 %r110, _ZZ18prepare_svd_kernelILi256E9PayoffPutEviiT0_PKdPiPdE9smem_svds;
shl.b32 %r101, %r111, 3;
add.s32 %r103, %r110, %r101;
ld.shared.f64 %fd465, [%r103];
mov.u32 %r104, %ctaid.x;
shl.b32 %r105, %r104, 4;
add.s32 %r106, %r105, %r111;
cvta.to.global.u64 %rd8, %rd14;
mul.wide.u32 %rd9, %r106, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd465;

$L__BB4_57:
ret;

}

.visible .entry _Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd(
.param .u32 _Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_0,
.param .align 8 .b8 _Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_1[8],
.param .u64 _Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_2,
.param .u64 _Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_3,
.param .u64 _Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_4,
.param .u64 _Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_5,
.param .u64 _Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_6
)
.maxntid 128, 1, 1
.minnctapersm 8
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<183>;
.reg .b64 %rd<51>;

	.shared .align 8 .b8 _ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE5lsums[24];

	.shared .align 8 .b8 _ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd[96];

ld.param.f64 %fd79, [_Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_1];
ld.param.u32 %r14, [_Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_0];
ld.param.u64 %rd16, [_Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_2];
ld.param.u64 %rd17, [_Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_3];
ld.param.u64 %rd18, [_Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_4];
ld.param.u64 %rd20, [_Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_5];
cvta.to.global.u64 %rd21, %rd20;
ld.global.nc.u32 %r15, [%rd21];
setp.ne.s32 %p1, %r15, 0;
@%p1 bra $L__BB5_30;

mov.u32 %r1, %tid.x;
setp.gt.u32 %p2, %r1, 11;
@%p2 bra $L__BB5_3;

cvta.to.global.u64 %rd22, %rd16;
mul.wide.u32 %rd23, %r1, 8;
add.s64 %rd24, %rd22, %rd23;
ld.global.nc.f64 %fd80, [%rd24];
shl.b32 %r16, %r1, 3;
mov.u32 %r17, _ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd;
add.s32 %r18, %r17, %r16;
st.shared.f64 [%r18], %fd80;

$L__BB5_3:
bar.sync 0;
ld.shared.f64 %fd1, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+8];
ld.shared.f64 %fd2, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+16];
ld.shared.f64 %fd3, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+24];
ld.shared.f64 %fd4, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+32];
ld.shared.f64 %fd5, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+40];
ld.shared.f64 %fd6, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+48];
ld.shared.f64 %fd7, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+56];
ld.shared.f64 %fd8, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+64];
ld.shared.f64 %fd9, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+72];
ld.shared.f64 %fd10, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+80];
ld.shared.f64 %fd11, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd+88];
ld.shared.f64 %fd12, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE10shared_svd];
setp.eq.f64 %p3, %fd12, 0d0000000000000000;
mov.f64 %fd180, 0d0000000000000000;
mov.f64 %fd160, %fd180;
@%p3 bra $L__BB5_5;

rcp.rn.f64 %fd160, %fd12;

$L__BB5_5:
setp.eq.f64 %p4, %fd3, 0d0000000000000000;
mov.f64 %fd161, %fd180;
@%p4 bra $L__BB5_7;

rcp.rn.f64 %fd161, %fd3;

$L__BB5_7:
setp.eq.f64 %p5, %fd5, 0d0000000000000000;
mov.f64 %fd162, %fd180;
@%p5 bra $L__BB5_9;

rcp.rn.f64 %fd162, %fd5;

$L__BB5_9:
mul.f64 %fd87, %fd160, %fd161;
mul.f64 %fd19, %fd1, %fd87;
mul.f64 %fd88, %fd160, %fd162;
mul.f64 %fd20, %fd2, %fd88;
mul.f64 %fd21, %fd4, %fd162;
mul.f64 %fd22, %fd6, %fd160;
mov.u32 %r19, %ctaid.x;
shl.b32 %r2, %r19, 7;
add.s32 %r47, %r2, %r1;
setp.ge.s32 %p6, %r47, %r14;
mov.f64 %fd181, %fd180;
mov.f64 %fd182, %fd180;
@%p6 bra $L__BB5_26;

not.b32 %r20, %r1;
add.s32 %r21, %r20, %r14;
sub.s32 %r22, %r21, %r2;
mov.u32 %r23, %nctaid.x;
shl.b32 %r24, %r23, 7;
div.u32 %r4, %r22, %r24;
add.s32 %r25, %r4, 1;
and.b32 %r46, %r25, 3;
setp.eq.s32 %p7, %r46, 0;
mov.f64 %fd91, 0d0000000000000000;
mov.f64 %fd182, %fd91;
mov.f64 %fd181, %fd91;
mov.f64 %fd180, %fd91;
@%p7 bra $L__BB5_15;

cvta.to.global.u64 %rd25, %rd18;
mul.wide.s32 %rd26, %r47, 8;
add.s64 %rd50, %rd25, %rd26;
cvta.to.global.u64 %rd27, %rd17;
add.s64 %rd49, %rd27, %rd26;

$L__BB5_12:
.pragma "nounroll";
ld.global.nc.f64 %fd97, [%rd49];
setp.leu.f64 %p8, %fd79, %fd97;
mul.f64 %fd98, %fd161, %fd97;
sub.f64 %fd99, %fd98, %fd19;
mul.f64 %fd100, %fd162, %fd97;
mul.f64 %fd101, %fd97, %fd100;
sub.f64 %fd102, %fd101, %fd20;
mul.f64 %fd103, %fd21, %fd99;
sub.f64 %fd27, %fd102, %fd103;
fma.rn.f64 %fd104, %fd7, %fd99, %fd22;
fma.rn.f64 %fd28, %fd8, %fd27, %fd104;
mul.f64 %fd105, %fd10, %fd27;
fma.rn.f64 %fd29, %fd9, %fd99, %fd105;
mov.f64 %fd166, %fd91;
@%p8 bra $L__BB5_14;

ld.global.nc.f64 %fd166, [%rd50];

$L__BB5_14:
fma.rn.f64 %fd180, %fd28, %fd166, %fd180;
fma.rn.f64 %fd181, %fd29, %fd166, %fd181;
mul.f64 %fd106, %fd11, %fd27;
fma.rn.f64 %fd182, %fd106, %fd166, %fd182;
add.s32 %r47, %r47, %r24;
mul.wide.s32 %rd28, %r24, 8;
add.s64 %rd50, %rd50, %rd28;
add.s64 %rd49, %rd49, %rd28;
add.s32 %r46, %r46, -1;
setp.ne.s32 %p9, %r46, 0;
@%p9 bra $L__BB5_12;

$L__BB5_15:
setp.lt.u32 %p10, %r4, 3;
@%p10 bra $L__BB5_26;

ld.param.u64 %rd47, [_Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_3];
mul.wide.s32 %rd7, %r24, 8;
cvta.to.global.u64 %rd8, %rd47;

$L__BB5_17:
cvt.s64.s32 %rd9, %r47;
mul.wide.s32 %rd29, %r47, 8;
add.s64 %rd10, %rd8, %rd29;
ld.global.nc.f64 %fd108, [%rd10];
setp.leu.f64 %p11, %fd79, %fd108;
mul.f64 %fd109, %fd161, %fd108;
sub.f64 %fd110, %fd109, %fd19;
mul.f64 %fd111, %fd162, %fd108;
mul.f64 %fd112, %fd108, %fd111;
sub.f64 %fd113, %fd112, %fd20;
mul.f64 %fd114, %fd21, %fd110;
sub.f64 %fd44, %fd113, %fd114;
fma.rn.f64 %fd115, %fd7, %fd110, %fd22;
fma.rn.f64 %fd45, %fd8, %fd44, %fd115;
mul.f64 %fd116, %fd10, %fd44;
fma.rn.f64 %fd46, %fd9, %fd110, %fd116;
mov.f64 %fd176, 0d0000000000000000;
@%p11 bra $L__BB5_19;

cvta.to.global.u64 %rd30, %rd18;
shl.b64 %rd31, %rd9, 3;
add.s64 %rd32, %rd30, %rd31;
ld.global.nc.f64 %fd176, [%rd32];

$L__BB5_19:
mov.f64 %fd177, 0d0000000000000000;
fma.rn.f64 %fd49, %fd45, %fd176, %fd180;
fma.rn.f64 %fd50, %fd46, %fd176, %fd181;
mul.f64 %fd118, %fd11, %fd44;
fma.rn.f64 %fd51, %fd118, %fd176, %fd182;
cvt.u32.u64 %r29, %rd9;
add.s32 %r30, %r29, %r24;
cvt.s64.s32 %rd11, %r30;
add.s64 %rd12, %rd10, %rd7;
ld.global.nc.f64 %fd119, [%rd12];
setp.leu.f64 %p12, %fd79, %fd119;
mul.f64 %fd120, %fd161, %fd119;
sub.f64 %fd121, %fd120, %fd19;
mul.f64 %fd122, %fd162, %fd119;
mul.f64 %fd123, %fd119, %fd122;
sub.f64 %fd124, %fd123, %fd20;
mul.f64 %fd125, %fd21, %fd121;
sub.f64 %fd52, %fd124, %fd125;
fma.rn.f64 %fd126, %fd7, %fd121, %fd22;
fma.rn.f64 %fd53, %fd8, %fd52, %fd126;
mul.f64 %fd127, %fd10, %fd52;
fma.rn.f64 %fd54, %fd9, %fd121, %fd127;
@%p12 bra $L__BB5_21;

cvta.to.global.u64 %rd33, %rd18;
shl.b64 %rd34, %rd11, 3;
add.s64 %rd35, %rd33, %rd34;
ld.global.nc.f64 %fd177, [%rd35];

$L__BB5_21:
mov.f64 %fd178, 0d0000000000000000;
fma.rn.f64 %fd57, %fd53, %fd177, %fd49;
fma.rn.f64 %fd58, %fd54, %fd177, %fd50;
mul.f64 %fd129, %fd11, %fd52;
fma.rn.f64 %fd59, %fd129, %fd177, %fd51;
cvt.u32.u64 %r31, %rd11;
add.s32 %r32, %r31, %r24;
cvt.s64.s32 %rd13, %r32;
add.s64 %rd14, %rd12, %rd7;
ld.global.nc.f64 %fd130, [%rd14];
setp.leu.f64 %p13, %fd79, %fd130;
mul.f64 %fd131, %fd161, %fd130;
sub.f64 %fd132, %fd131, %fd19;
mul.f64 %fd133, %fd162, %fd130;
mul.f64 %fd134, %fd130, %fd133;
sub.f64 %fd135, %fd134, %fd20;
mul.f64 %fd136, %fd21, %fd132;
sub.f64 %fd60, %fd135, %fd136;
fma.rn.f64 %fd137, %fd7, %fd132, %fd22;
fma.rn.f64 %fd61, %fd8, %fd60, %fd137;
mul.f64 %fd138, %fd10, %fd60;
fma.rn.f64 %fd62, %fd9, %fd132, %fd138;
@%p13 bra $L__BB5_23;

cvta.to.global.u64 %rd36, %rd18;
shl.b64 %rd37, %rd13, 3;
add.s64 %rd38, %rd36, %rd37;
ld.global.nc.f64 %fd178, [%rd38];

$L__BB5_23:
mov.f64 %fd179, 0d0000000000000000;
fma.rn.f64 %fd65, %fd61, %fd178, %fd57;
fma.rn.f64 %fd66, %fd62, %fd178, %fd58;
mul.f64 %fd140, %fd11, %fd60;
fma.rn.f64 %fd67, %fd140, %fd178, %fd59;
cvt.u32.u64 %r33, %rd13;
add.s32 %r34, %r33, %r24;
cvt.s64.s32 %rd15, %r34;
add.s64 %rd39, %rd14, %rd7;
ld.global.nc.f64 %fd141, [%rd39];
setp.leu.f64 %p14, %fd79, %fd141;
mul.f64 %fd142, %fd161, %fd141;
sub.f64 %fd143, %fd142, %fd19;
mul.f64 %fd144, %fd162, %fd141;
mul.f64 %fd145, %fd141, %fd144;
sub.f64 %fd146, %fd145, %fd20;
mul.f64 %fd147, %fd21, %fd143;
sub.f64 %fd68, %fd146, %fd147;
fma.rn.f64 %fd148, %fd7, %fd143, %fd22;
fma.rn.f64 %fd69, %fd8, %fd68, %fd148;
mul.f64 %fd149, %fd10, %fd68;
fma.rn.f64 %fd70, %fd9, %fd143, %fd149;
@%p14 bra $L__BB5_25;

cvta.to.global.u64 %rd40, %rd18;
shl.b64 %rd41, %rd15, 3;
add.s64 %rd42, %rd40, %rd41;
ld.global.nc.f64 %fd179, [%rd42];

$L__BB5_25:
ld.param.u32 %r44, [_Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_0];
fma.rn.f64 %fd180, %fd69, %fd179, %fd65;
fma.rn.f64 %fd181, %fd70, %fd179, %fd66;
mul.f64 %fd150, %fd11, %fd68;
fma.rn.f64 %fd182, %fd150, %fd179, %fd67;
cvt.u32.u64 %r35, %rd15;
add.s32 %r47, %r35, %r24;
setp.lt.s32 %p15, %r47, %r44;
@%p15 bra $L__BB5_17;

$L__BB5_26:
mov.u32 %r42, %tid.x;
setp.ne.s32 %p16, %r42, 0;
@%p16 bra $L__BB5_28;

mov.u64 %rd43, 0;
st.shared.u64 [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE5lsums], %rd43;
st.shared.u64 [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE5lsums+8], %rd43;
st.shared.u64 [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE5lsums+16], %rd43;

$L__BB5_28:
bar.sync 0;
mov.u32 %r38, _ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE5lsums;
atom.shared.add.f64 %fd151, [%r38], %fd180;
add.s32 %r39, %r38, 8;
atom.shared.add.f64 %fd152, [%r39], %fd181;
add.s32 %r40, %r38, 16;
atom.shared.add.f64 %fd153, [%r40], %fd182;
bar.sync 0;
@%p16 bra $L__BB5_30;

mov.u32 %r43, %ctaid.x;
ld.param.u64 %rd48, [_Z27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPd_param_6];
ld.shared.f64 %fd154, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE5lsums];
cvta.to.global.u64 %rd44, %rd48;
mul.wide.u32 %rd45, %r43, 8;
add.s64 %rd46, %rd44, %rd45;
st.global.f64 [%rd46], %fd154;
ld.shared.f64 %fd155, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE5lsums+8];
st.global.f64 [%rd46+1024], %fd155;
ld.shared.f64 %fd156, [_ZZ27compute_partial_beta_kernelILi128E9PayoffPutEviT0_PKdS3_S3_PKiPdE5lsums+16];
st.global.f64 [%rd46+2048], %fd156;

$L__BB5_30:
ret;

}

.visible .entry _Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd(
.param .u32 _Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_0,
.param .align 8 .b8 _Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_1[8],
.param .f64 _Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_2,
.param .u64 _Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_3,
.param .u64 _Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_4,
.param .u64 _Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_5,
.param .u64 _Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_6
)
.maxntid 128, 1, 1
{
.reg .pred %p<26>;
.reg .b32 %r<59>;
.reg .f64 %fd<69>;
.reg .b64 %rd<45>;


ld.param.f64 %fd5, [_Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_1];
ld.param.u32 %r24, [_Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_0];
ld.param.f64 %fd6, [_Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_2];
ld.param.u64 %rd19, [_Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_3];
ld.param.u64 %rd16, [_Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_4];
ld.param.u64 %rd17, [_Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_5];
ld.param.u64 %rd18, [_Z22update_cashflow_kernelILi128E9PayoffPutEviT0_dPKdS3_PKiPd_param_6];
cvta.to.global.u64 %rd20, %rd19;
mov.u32 %r25, %nctaid.x;
shl.b32 %r1, %r25, 7;
ld.global.nc.f64 %fd1, [%rd20];
ld.global.nc.f64 %fd2, [%rd20+8];
ld.global.nc.f64 %fd3, [%rd20+16];
mov.u32 %r26, %ctaid.x;
shl.b32 %r2, %r26, 7;
mov.u32 %r3, %tid.x;
add.s32 %r53, %r2, %r3;
setp.ge.s32 %p1, %r53, %r24;
@%p1 bra $L__BB6_14;

cvta.to.global.u64 %rd21, %rd17;
ld.global.nc.u32 %r28, [%rd21];
setp.eq.s32 %p2, %r28, 0;
not.b32 %r29, %r3;
add.s32 %r30, %r29, %r24;
sub.s32 %r31, %r30, %r2;
div.u32 %r4, %r31, %r1;
add.s32 %r32, %r4, 1;
and.b32 %r52, %r32, 3;
@%p2 bra $L__BB6_8;

setp.eq.s32 %p3, %r52, 0;
@%p3 bra $L__BB6_5;

add.s32 %r53, %r2, %r3;
cvta.to.global.u64 %rd22, %rd18;
mul.wide.s32 %rd23, %r53, 8;
add.s64 %rd42, %rd22, %rd23;
mul.wide.s32 %rd2, %r1, 8;

$L__BB6_4:
.pragma "nounroll";
ld.global.f64 %fd7, [%rd42];
mul.f64 %fd8, %fd7, %fd6;
st.global.f64 [%rd42], %fd8;
add.s32 %r53, %r53, %r1;
add.s64 %rd42, %rd42, %rd2;
add.s32 %r52, %r52, -1;
setp.ne.s32 %p4, %r52, 0;
@%p4 bra $L__BB6_4;

$L__BB6_5:
setp.lt.u32 %p5, %r4, 3;
@%p5 bra $L__BB6_14;

mul.wide.s32 %rd5, %r1, 8;
cvta.to.global.u64 %rd6, %rd18;

$L__BB6_7:
mul.wide.s32 %rd24, %r53, 8;
add.s64 %rd25, %rd6, %rd24;
ld.global.f64 %fd9, [%rd25];
mul.f64 %fd10, %fd9, %fd6;
st.global.f64 [%rd25], %fd10;
add.s64 %rd26, %rd25, %rd5;
ld.global.f64 %fd11, [%rd26];
mul.f64 %fd12, %fd11, %fd6;
st.global.f64 [%rd26], %fd12;
add.s32 %r39, %r53, %r1;
add.s32 %r40, %r39, %r1;
add.s64 %rd27, %rd26, %rd5;
ld.global.f64 %fd13, [%rd27];
mul.f64 %fd14, %fd13, %fd6;
st.global.f64 [%rd27], %fd14;
add.s32 %r41, %r40, %r1;
add.s64 %rd28, %rd27, %rd5;
ld.global.f64 %fd15, [%rd28];
mul.f64 %fd16, %fd15, %fd6;
st.global.f64 [%rd28], %fd16;
add.s32 %r53, %r41, %r1;
setp.lt.s32 %p6, %r53, %r24;
@%p6 bra $L__BB6_7;
bra.uni $L__BB6_14;

$L__BB6_8:
setp.eq.s32 %p7, %r52, 0;
add.s32 %r57, %r2, %r3;
@%p7 bra $L__BB6_11;

add.s32 %r57, %r2, %r3;
cvta.to.global.u64 %rd29, %rd16;
mul.wide.s32 %rd30, %r57, 8;
add.s64 %rd44, %rd29, %rd30;
mul.wide.s32 %rd8, %r1, 8;
cvta.to.global.u64 %rd31, %rd18;
add.s64 %rd43, %rd31, %rd30;
mov.f64 %fd22, 0d0000000000000000;

$L__BB6_10:
.pragma "nounroll";
ld.global.f64 %fd17, [%rd43];
mul.f64 %fd18, %fd17, %fd6;
ld.global.nc.f64 %fd19, [%rd44];
mul.f64 %fd20, %fd19, %fd19;
sub.f64 %fd21, %fd5, %fd19;
max.f64 %fd23, %fd21, %fd22;
fma.rn.f64 %fd24, %fd2, %fd19, %fd1;
fma.rn.f64 %fd25, %fd3, %fd20, %fd24;
mul.f64 %fd26, %fd25, %fd6;
setp.le.f64 %p8, %fd23, 0d3E45798EE2308C3A;
setp.le.f64 %p9, %fd23, %fd26;
or.pred %p10, %p8, %p9;
selp.f64 %fd27, %fd18, %fd23, %p10;
st.global.f64 [%rd43], %fd27;
add.s32 %r57, %r57, %r1;
add.s64 %rd44, %rd44, %rd8;
add.s64 %rd43, %rd43, %rd8;
add.s32 %r52, %r52, -1;
setp.ne.s32 %p11, %r52, 0;
@%p11 bra $L__BB6_10;

$L__BB6_11:
setp.lt.u32 %p12, %r4, 3;
@%p12 bra $L__BB6_14;

mul.wide.s32 %rd14, %r1, 8;
cvta.to.global.u64 %rd15, %rd16;
cvta.to.global.u64 %rd32, %rd18;
mov.f64 %fd33, 0d0000000000000000;

$L__BB6_13:
mul.wide.s32 %rd33, %r57, 8;
add.s64 %rd34, %rd32, %rd33;
ld.global.f64 %fd28, [%rd34];
mul.f64 %fd29, %fd28, %fd6;
add.s64 %rd35, %rd15, %rd33;
ld.global.nc.f64 %fd30, [%rd35];
mul.f64 %fd31, %fd30, %fd30;
sub.f64 %fd32, %fd5, %fd30;
max.f64 %fd34, %fd32, %fd33;
fma.rn.f64 %fd35, %fd2, %fd30, %fd1;
fma.rn.f64 %fd36, %fd3, %fd31, %fd35;
mul.f64 %fd37, %fd36, %fd6;
setp.le.f64 %p13, %fd34, 0d3E45798EE2308C3A;
setp.le.f64 %p14, %fd34, %fd37;
or.pred %p15, %p13, %p14;
selp.f64 %fd38, %fd29, %fd34, %p15;
st.global.f64 [%rd34], %fd38;
add.s64 %rd36, %rd34, %rd14;
ld.global.f64 %fd39, [%rd36];
mul.f64 %fd40, %fd39, %fd6;
add.s64 %rd37, %rd35, %rd14;
ld.global.nc.f64 %fd41, [%rd37];
mul.f64 %fd42, %fd41, %fd41;
sub.f64 %fd43, %fd5, %fd41;
max.f64 %fd44, %fd43, %fd33;
fma.rn.f64 %fd45, %fd2, %fd41, %fd1;
fma.rn.f64 %fd46, %fd3, %fd42, %fd45;
mul.f64 %fd47, %fd46, %fd6;
setp.le.f64 %p16, %fd44, 0d3E45798EE2308C3A;
setp.le.f64 %p17, %fd44, %fd47;
or.pred %p18, %p16, %p17;
selp.f64 %fd48, %fd40, %fd44, %p18;
st.global.f64 [%rd36], %fd48;
add.s32 %r48, %r57, %r1;
add.s32 %r49, %r48, %r1;
add.s64 %rd38, %rd36, %rd14;
ld.global.f64 %fd49, [%rd38];
mul.f64 %fd50, %fd49, %fd6;
add.s64 %rd39, %rd37, %rd14;
ld.global.nc.f64 %fd51, [%rd39];
mul.f64 %fd52, %fd51, %fd51;
sub.f64 %fd53, %fd5, %fd51;
max.f64 %fd54, %fd53, %fd33;
fma.rn.f64 %fd55, %fd2, %fd51, %fd1;
fma.rn.f64 %fd56, %fd3, %fd52, %fd55;
mul.f64 %fd57, %fd56, %fd6;
setp.le.f64 %p19, %fd54, 0d3E45798EE2308C3A;
setp.le.f64 %p20, %fd54, %fd57;
or.pred %p21, %p19, %p20;
selp.f64 %fd58, %fd50, %fd54, %p21;
st.global.f64 [%rd38], %fd58;
add.s32 %r50, %r49, %r1;
add.s64 %rd40, %rd38, %rd14;
ld.global.f64 %fd59, [%rd40];
mul.f64 %fd60, %fd59, %fd6;
add.s64 %rd41, %rd39, %rd14;
ld.global.nc.f64 %fd61, [%rd41];
mul.f64 %fd62, %fd61, %fd61;
sub.f64 %fd63, %fd5, %fd61;
max.f64 %fd64, %fd63, %fd33;
fma.rn.f64 %fd65, %fd2, %fd61, %fd1;
fma.rn.f64 %fd66, %fd3, %fd62, %fd65;
mul.f64 %fd67, %fd66, %fd6;
setp.le.f64 %p22, %fd64, 0d3E45798EE2308C3A;
setp.le.f64 %p23, %fd64, %fd67;
or.pred %p24, %p22, %p23;
selp.f64 %fd68, %fd60, %fd64, %p24;
st.global.f64 [%rd40], %fd68;
add.s32 %r57, %r50, %r1;
setp.lt.s32 %p25, %r57, %r24;
@%p25 bra $L__BB6_13;

$L__BB6_14:
ret;

}

.visible .entry _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd(
.param .u32 _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_0,
.param .u32 _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_1,
.param .align 8 .b8 _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_2[8],
.param .f64 _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_3,
.param .f64 _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_4,
.param .f64 _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_5,
.param .f64 _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_6,
.param .u64 _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_7,
.param .u64 _Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_8
)
.maxntid 256, 1, 1
{
.reg .pred %p<6>;
.reg .f32 %f<3>;
.reg .b32 %r<27>;
.reg .f64 %fd<59>;
.reg .b64 %rd<15>;


ld.param.f64 %fd11, [_Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_2];
ld.param.u32 %r7, [_Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_0];
ld.param.u32 %r8, [_Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_1];
ld.param.f64 %fd12, [_Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_3];
ld.param.f64 %fd57, [_Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_4];
ld.param.f64 %fd14, [_Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_5];
ld.param.f64 %fd15, [_Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_6];
ld.param.u64 %rd7, [_Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_7];
ld.param.u64 %rd8, [_Z21generate_paths_kernelILi256E10PayoffCallEviiT0_ddddPKdPd_param_8];
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 8;
mov.u32 %r11, %tid.x;
add.s32 %r1, %r10, %r11;
setp.ge.s32 %p1, %r1, %r8;
@%p1 bra $L__BB7_7;

mul.f64 %fd16, %fd15, 0dBFE0000000000000;
fma.rn.f64 %fd17, %fd16, %fd15, %fd14;
mul.f64 %fd1, %fd17, %fd12;
sqrt.rn.f64 %fd18, %fd12;
mul.f64 %fd2, %fd18, %fd15;
cvta.to.global.u64 %rd9, %rd8;
mul.wide.s32 %rd10, %r1, 8;
add.s64 %rd14, %rd9, %rd10;
cvta.to.global.u64 %rd11, %rd7;
add.s64 %rd13, %rd11, %rd10;
mov.u32 %r26, 0;
add.s32 %r25, %r7, -1;
bra.uni $L__BB7_2;

$L__BB7_8:
st.global.f64 [%rd14], %fd57;
add.s32 %r26, %r26, 1;
mul.wide.s32 %rd12, %r8, 8;
add.s64 %rd14, %rd14, %rd12;
add.s64 %rd13, %rd13, %rd12;

$L__BB7_2:
ld.global.nc.f64 %fd19, [%rd13];
fma.rn.f64 %fd5, %fd2, %fd19, %fd1;
mov.f64 %fd20, 0d4338000000000000;
mov.f64 %fd21, 0d3FF71547652B82FE;
fma.rn.f64 %fd22, %fd5, %fd21, %fd20;
{
.reg .b32 %temp; 
mov.b64 {%r3, %temp}, %fd22;
}
mov.f64 %fd23, 0dC338000000000000;
add.rn.f64 %fd24, %fd22, %fd23;
mov.f64 %fd25, 0dBFE62E42FEFA39EF;
fma.rn.f64 %fd26, %fd24, %fd25, %fd5;
mov.f64 %fd27, 0dBC7ABC9E3B39803F;
fma.rn.f64 %fd28, %fd24, %fd27, %fd26;
mov.f64 %fd29, 0d3E928AF3FCA213EA;
mov.f64 %fd30, 0d3E5ADE1569CE2BDF;
fma.rn.f64 %fd31, %fd30, %fd28, %fd29;
mov.f64 %fd32, 0d3EC71DEE62401315;
fma.rn.f64 %fd33, %fd31, %fd28, %fd32;
mov.f64 %fd34, 0d3EFA01997C89EB71;
fma.rn.f64 %fd35, %fd33, %fd28, %fd34;
mov.f64 %fd36, 0d3F2A01A014761F65;
fma.rn.f64 %fd37, %fd35, %fd28, %fd36;
mov.f64 %fd38, 0d3F56C16C1852B7AF;
fma.rn.f64 %fd39, %fd37, %fd28, %fd38;
mov.f64 %fd40, 0d3F81111111122322;
fma.rn.f64 %fd41, %fd39, %fd28, %fd40;
mov.f64 %fd42, 0d3FA55555555502A1;
fma.rn.f64 %fd43, %fd41, %fd28, %fd42;
mov.f64 %fd44, 0d3FC5555555555511;
fma.rn.f64 %fd45, %fd43, %fd28, %fd44;
mov.f64 %fd46, 0d3FE000000000000B;
fma.rn.f64 %fd47, %fd45, %fd28, %fd46;
mov.f64 %fd48, 0d3FF0000000000000;
fma.rn.f64 %fd49, %fd47, %fd28, %fd48;
fma.rn.f64 %fd50, %fd49, %fd28, %fd48;
{
.reg .b32 %temp; 
mov.b64 {%r4, %temp}, %fd50;
}
{
.reg .b32 %temp; 
mov.b64 {%temp, %r5}, %fd50;
}
shl.b32 %r13, %r3, 20;
add.s32 %r14, %r5, %r13;
mov.b64 %fd58, {%r4, %r14};
{
.reg .b32 %temp; 
mov.b64 {%temp, %r15}, %fd5;
}
mov.b32 %f2, %r15;
abs.ftz.f32 %f1, %f2;
setp.lt.ftz.f32 %p2, %f1, 0f4086232B;
@%p2 bra $L__BB7_5;

setp.lt.f64 %p3, %fd5, 0d0000000000000000;
add.f64 %fd51, %fd5, 0d7FF0000000000000;
selp.f64 %fd58, 0d0000000000000000, %fd51, %p3;
setp.geu.ftz.f32 %p4, %f1, 0f40874800;
@%p4 bra $L__BB7_5;

shr.u32 %r16, %r3, 31;
add.s32 %r17, %r3, %r16;
shr.s32 %r18, %r17, 1;
shl.b32 %r19, %r18, 20;
add.s32 %r20, %r5, %r19;
mov.b64 %fd52, {%r4, %r20};
sub.s32 %r21, %r3, %r18;
shl.b32 %r22, %r21, 20;
add.s32 %r23, %r22, 1072693248;
mov.u32 %r24, 0;
mov.b64 %fd53, {%r24, %r23};
mul.f64 %fd58, %fd52, %fd53;

$L__BB7_5:
setp.lt.s32 %p5, %r26, %r25;
mul.f64 %fd57, %fd57, %fd58;
@%p5 bra $L__BB7_8;

sub.f64 %fd54, %fd57, %fd11;
mov.f64 %fd55, 0d0000000000000000;
max.f64 %fd56, %fd54, %fd55;
st.global.f64 [%rd14], %fd56;

$L__BB7_7:
ret;

}

.visible .entry _Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd(
.param .u32 _Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_0,
.param .u32 _Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_1,
.param .align 8 .b8 _Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_2[8],
.param .u64 _Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_3,
.param .u64 _Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_4,
.param .u64 _Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_5
)
.maxntid 256, 1, 1
.minnctapersm 4
{
.reg .pred %p<41>;
.reg .b32 %r<121>;
.reg .f64 %fd<545>;
.reg .b64 %rd<15>;

	.shared .align 4 .b8 _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE10scan_input[1024];

	.shared .align 4 .b8 _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE11scan_output[1028];

	.shared .align 16 .b8 _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE5lsums[32];

	.shared .align 4 .u32 _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE4lsum;

	.shared .align 8 .b8 _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds[96];

ld.param.f64 %fd165, [_Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_2];
ld.param.u32 %r21, [_Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_0];
ld.param.u32 %r22, [_Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_1];
ld.param.u64 %rd1, [_Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_3];
ld.param.u64 %rd2, [_Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_4];
mov.u32 %r1, %tid.x;
setp.gt.u32 %p1, %r1, 11;
shl.b32 %r23, %r1, 3;
mov.u32 %r24, _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds;
add.s32 %r2, %r24, %r23;
@%p1 bra $L__BB8_2;

mov.u64 %rd4, 0;
st.shared.u64 [%r2], %rd4;

$L__BB8_2:
bar.sync 0;
setp.ge.s32 %p2, %r1, %r21;
mov.u32 %r118, 0;
mov.f64 %fd470, 0d0000000000000000;
mov.f64 %fd471, %fd470;
mov.f64 %fd472, %fd470;
mov.f64 %fd473, %fd470;
@%p2 bra $L__BB8_16;

cvta.to.global.u64 %rd5, %rd1;
mov.u32 %r112, %r1;
mov.u32 %r117, %r118;

$L__BB8_4:
setp.ne.s32 %p3, %r1, 0;
mov.u32 %r29, %ctaid.x;
mad.lo.s32 %r30, %r29, %r21, %r112;
mul.wide.s32 %rd6, %r30, 8;
add.s64 %rd7, %rd5, %rd6;
ld.global.nc.f64 %fd6, [%rd7];
setp.lt.f64 %p4, %fd165, %fd6;
selp.u32 %r6, 1, 0, %p4;
shl.b32 %r31, %r1, 2;
mov.u32 %r32, _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE10scan_input;
add.s32 %r33, %r32, %r31;
st.shared.u32 [%r33], %r6;
bar.sync 0;
@%p3 bra $L__BB8_7;

mov.u32 %r115, 0;
st.shared.u32 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE11scan_output], %r115;
mov.u32 %r116, 1;

$L__BB8_6:
shl.b32 %r36, %r116, 2;
add.s32 %r38, %r32, %r36;
ld.shared.u32 %r39, [%r38+-4];
add.s32 %r40, %r39, %r115;
mov.u32 %r41, _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE11scan_output;
add.s32 %r42, %r41, %r36;
st.shared.u32 [%r42], %r40;
ld.shared.u32 %r43, [%r38];
add.s32 %r44, %r43, %r40;
st.shared.u32 [%r42+4], %r44;
ld.shared.u32 %r45, [%r38+4];
add.s32 %r46, %r45, %r44;
st.shared.u32 [%r42+8], %r46;
ld.shared.u32 %r47, [%r38+8];
add.s32 %r48, %r47, %r46;
st.shared.u32 [%r42+12], %r48;
ld.shared.u32 %r49, [%r38+12];
add.s32 %r50, %r49, %r48;
st.shared.u32 [%r42+16], %r50;
ld.shared.u32 %r51, [%r38+16];
add.s32 %r52, %r51, %r50;
st.shared.u32 [%r42+20], %r52;
ld.shared.u32 %r53, [%r38+20];
add.s32 %r54, %r53, %r52;
st.shared.u32 [%r42+24], %r54;
ld.shared.u32 %r55, [%r38+24];
add.s32 %r56, %r55, %r54;
st.shared.u32 [%r42+28], %r56;
ld.shared.u32 %r57, [%r38+28];
add.s32 %r58, %r57, %r56;
st.shared.u32 [%r42+32], %r58;
ld.shared.u32 %r59, [%r38+32];
add.s32 %r60, %r59, %r58;
st.shared.u32 [%r42+36], %r60;
ld.shared.u32 %r61, [%r38+36];
add.s32 %r62, %r61, %r60;
st.shared.u32 [%r42+40], %r62;
ld.shared.u32 %r63, [%r38+40];
add.s32 %r64, %r63, %r62;
st.shared.u32 [%r42+44], %r64;
ld.shared.u32 %r65, [%r38+44];
add.s32 %r66, %r65, %r64;
st.shared.u32 [%r42+48], %r66;
ld.shared.u32 %r67, [%r38+48];
add.s32 %r68, %r67, %r66;
st.shared.u32 [%r42+52], %r68;
ld.shared.u32 %r69, [%r38+52];
add.s32 %r70, %r69, %r68;
st.shared.u32 [%r42+56], %r70;
ld.shared.u32 %r71, [%r38+56];
add.s32 %r115, %r71, %r70;
st.shared.u32 [%r42+60], %r115;
add.s32 %r116, %r116, 16;
setp.ne.s32 %p5, %r116, 257;
@%p5 bra $L__BB8_6;

$L__BB8_7:
bar.sync 0;
setp.gt.s32 %p6, %r117, 2;
@%p6 bra $L__BB8_11;

ld.shared.u32 %r11, [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE11scan_output+1024];
mov.u32 %r72, _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE11scan_output;
setp.geu.f64 %p7, %fd165, %fd6;
mov.u32 %r73, %tid.x;
shl.b32 %r74, %r73, 2;
add.s32 %r75, %r72, %r74;
ld.shared.u32 %r76, [%r75];
add.s32 %r12, %r76, %r117;
setp.gt.s32 %p8, %r12, 2;
or.pred %p9, %p7, %p8;
@%p9 bra $L__BB8_10;

shl.b32 %r77, %r12, 3;
add.s32 %r79, %r24, %r77;
st.shared.f64 [%r79], %fd6;

$L__BB8_10:
bar.sync 0;
add.s32 %r117, %r11, %r117;

$L__BB8_11:
mov.u32 %r80, %tid.x;
setp.ne.s32 %p10, %r80, 0;
@%p10 bra $L__BB8_13;

mov.u32 %r81, 0;
st.shared.u32 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE4lsum], %r81;

$L__BB8_13:
bar.sync 0;
mov.u32 %r82, _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE4lsum;
atom.shared.or.b32 %r83, [%r82], %r6;
bar.sync 0;
ld.shared.u32 %r84, [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE4lsum];
setp.eq.s32 %p11, %r84, 0;
@%p11 bra $L__BB8_15;

add.s32 %r118, %r118, %r6;
selp.f64 %fd174, %fd6, 0d0000000000000000, %p4;
mul.f64 %fd175, %fd6, %fd6;
selp.f64 %fd176, %fd175, 0d0000000000000000, %p4;
add.f64 %fd473, %fd473, %fd174;
add.f64 %fd472, %fd472, %fd176;
fma.rn.f64 %fd471, %fd176, %fd174, %fd471;
fma.rn.f64 %fd470, %fd176, %fd176, %fd470;

$L__BB8_15:
add.s32 %r112, %r112, 256;
setp.lt.s32 %p13, %r112, %r21;
@%p13 bra $L__BB8_4;

$L__BB8_16:
mov.u32 %r85, %tid.x;
setp.ne.s32 %p14, %r85, 0;
@%p14 bra $L__BB8_18;

mov.u32 %r86, 0;
st.shared.u32 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE4lsum], %r86;

$L__BB8_18:
setp.eq.s32 %p15, %r85, 0;
bar.sync 0;
mov.u32 %r88, _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE4lsum;
atom.shared.add.u32 %r89, [%r88], %r118;
bar.sync 0;
ld.shared.u32 %r90, [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE4lsum];
setp.lt.s32 %p16, %r90, %r22;
and.pred %p17, %p15, %p16;
@%p17 bra $L__BB8_56;
bra.uni $L__BB8_19;

$L__BB8_56:
mov.u32 %r107, %ctaid.x;
cvta.to.global.u64 %rd11, %rd2;
mul.wide.u32 %rd12, %r107, 4;
add.s64 %rd13, %rd11, %rd12;
mov.u32 %r108, 1;
st.global.u32 [%rd13], %r108;
bra.uni $L__BB8_57;

$L__BB8_19:
@%p14 bra $L__BB8_21;

mov.f64 %fd177, 0d0000000000000000;
st.shared.v2.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE5lsums], {%fd177, %fd177};
st.shared.v2.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE5lsums+16], {%fd177, %fd177};

$L__BB8_21:
bar.sync 0;
mov.u32 %r93, _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE5lsums;
atom.shared.add.f64 %fd178, [%r93], %fd473;
add.s32 %r94, %r93, 8;
atom.shared.add.f64 %fd179, [%r94], %fd472;
add.s32 %r95, %r93, 16;
atom.shared.add.f64 %fd180, [%r95], %fd471;
add.s32 %r96, %r93, 24;
atom.shared.add.f64 %fd181, [%r96], %fd470;
bar.sync 0;
@%p14 bra $L__BB8_54;

ld.shared.u32 %r97, [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE4lsum];
ld.shared.f64 %fd183, [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+8];
ld.shared.f64 %fd19, [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+16];
ld.shared.f64 %fd184, [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds];
mul.f64 %fd185, %fd184, %fd184;
ld.shared.v2.f64 {%fd186, %fd187}, [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE5lsums];
sub.f64 %fd190, %fd186, %fd184;
sub.f64 %fd191, %fd187, %fd185;
ld.shared.v2.f64 {%fd192, %fd193}, [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE5lsums+16];
mul.f64 %fd196, %fd184, %fd185;
sub.f64 %fd197, %fd192, %fd196;
mul.f64 %fd198, %fd185, %fd185;
sub.f64 %fd20, %fd193, %fd198;
cvt.rn.f64.s32 %fd21, %r97;
add.f64 %fd199, %fd21, 0dBFF0000000000000;
mov.f64 %fd200, 0d3FF0000000000000;
sqrt.rn.f64 %fd22, %fd21;
neg.f64 %fd201, %fd199;
add.f64 %fd202, %fd22, 0d3FF0000000000000;
div.rn.f64 %fd483, %fd201, %fd202;
mul.f64 %fd203, %fd483, %fd483;
fma.rn.f64 %fd204, %fd483, %fd483, %fd203;
add.f64 %fd205, %fd199, %fd203;
div.rn.f64 %fd206, %fd204, %fd205;
rcp.rn.f64 %fd479, %fd483;
sub.f64 %fd207, %fd200, %fd206;
mul.f64 %fd208, %fd479, %fd206;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds], %fd22;
mul.f64 %fd209, %fd184, %fd207;
mul.f64 %fd210, %fd190, %fd208;
sub.f64 %fd25, %fd209, %fd210;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+8], %fd25;
mul.f64 %fd211, %fd185, %fd207;
mul.f64 %fd212, %fd191, %fd208;
sub.f64 %fd26, %fd211, %fd212;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+16], %fd26;
mul.f64 %fd213, %fd479, %fd208;
mul.f64 %fd214, %fd190, %fd213;
fma.rn.f64 %fd27, %fd184, %fd208, %fd214;
mul.f64 %fd215, %fd191, %fd213;
fma.rn.f64 %fd28, %fd185, %fd208, %fd215;
mul.f64 %fd29, %fd183, %fd183;
sub.f64 %fd30, %fd190, %fd183;
sub.f64 %fd31, %fd191, %fd29;
mul.f64 %fd216, %fd183, %fd29;
sub.f64 %fd32, %fd197, %fd216;
sub.f64 %fd33, %fd183, %fd27;
add.f64 %fd217, %fd27, %fd27;
mul.f64 %fd218, %fd30, %fd217;
sub.f64 %fd219, %fd31, %fd218;
add.f64 %fd220, %fd21, 0dC000000000000000;
mul.f64 %fd34, %fd220, %fd27;
fma.rn.f64 %fd35, %fd27, %fd34, %fd219;
abs.f64 %fd221, %fd35;
setp.lt.f64 %p20, %fd221, 0d3C9CD2B297D889BC;
mov.f64 %fd182, 0d0000000000000000;
mov.f64 %fd481, %fd182;
@%p20 bra $L__BB8_27;

fma.rn.f64 %fd222, %fd33, %fd33, %fd35;
sqrt.rn.f64 %fd36, %fd222;
setp.gtu.f64 %p21, %fd33, 0d0000000000000000;
@%p21 bra $L__BB8_25;
bra.uni $L__BB8_24;

$L__BB8_25:
neg.f64 %fd223, %fd35;
add.f64 %fd224, %fd33, %fd36;
div.rn.f64 %fd483, %fd223, %fd224;
bra.uni $L__BB8_26;

$L__BB8_24:
sub.f64 %fd483, %fd33, %fd36;

$L__BB8_26:
mul.f64 %fd225, %fd483, %fd483;
fma.rn.f64 %fd226, %fd483, %fd483, %fd225;
add.f64 %fd227, %fd35, %fd225;
div.rn.f64 %fd481, %fd226, %fd227;
rcp.rn.f64 %fd479, %fd483;

$L__BB8_27:
mul.f64 %fd229, %fd31, %fd27;
sub.f64 %fd230, %fd32, %fd229;
mul.f64 %fd231, %fd30, %fd28;
sub.f64 %fd232, %fd230, %fd231;
fma.rn.f64 %fd233, %fd28, %fd34, %fd232;
mul.f64 %fd234, %fd479, %fd481;
mul.f64 %fd235, %fd233, %fd234;
sub.f64 %fd236, %fd29, %fd28;
mul.f64 %fd237, %fd479, %fd235;
fma.rn.f64 %fd238, %fd236, %fd234, %fd237;
mul.f64 %fd239, %fd27, %fd238;
sub.f64 %fd240, %fd239, %fd28;
sub.f64 %fd242, %fd200, %fd481;
mul.f64 %fd243, %fd33, %fd242;
mul.f64 %fd244, %fd35, %fd234;
sub.f64 %fd45, %fd243, %fd244;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+24], %fd45;
mul.f64 %fd245, %fd236, %fd242;
sub.f64 %fd46, %fd245, %fd235;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+32], %fd46;
mul.f64 %fd246, %fd19, %fd19;
sub.f64 %fd247, %fd31, %fd246;
mul.f64 %fd248, %fd19, %fd246;
sub.f64 %fd249, %fd32, %fd248;
mul.f64 %fd250, %fd246, %fd246;
mul.f64 %fd251, %fd29, %fd29;
sub.f64 %fd252, %fd20, %fd251;
sub.f64 %fd253, %fd252, %fd250;
mul.f64 %fd254, %fd19, %fd238;
sub.f64 %fd255, %fd246, %fd254;
add.f64 %fd47, %fd255, %fd240;
add.f64 %fd256, %fd238, %fd238;
mul.f64 %fd257, %fd249, %fd256;
sub.f64 %fd258, %fd253, %fd257;
add.f64 %fd259, %fd240, %fd240;
fma.rn.f64 %fd260, %fd238, %fd238, %fd259;
fma.rn.f64 %fd261, %fd247, %fd260, %fd258;
mul.f64 %fd262, %fd256, %fd240;
sub.f64 %fd263, %fd30, %fd19;
mul.f64 %fd264, %fd263, %fd262;
sub.f64 %fd265, %fd261, %fd264;
add.f64 %fd266, %fd21, 0dC008000000000000;
mul.f64 %fd267, %fd266, %fd240;
fma.rn.f64 %fd48, %fd240, %fd267, %fd265;
abs.f64 %fd268, %fd48;
setp.lt.f64 %p22, %fd268, 0d3D719799812DEA11;
mov.f64 %fd484, %fd182;
@%p22 bra $L__BB8_32;

fma.rn.f64 %fd269, %fd47, %fd47, %fd48;
sqrt.rn.f64 %fd49, %fd269;
setp.gtu.f64 %p23, %fd47, 0d0000000000000000;
@%p23 bra $L__BB8_30;
bra.uni $L__BB8_29;

$L__BB8_30:
neg.f64 %fd270, %fd48;
add.f64 %fd271, %fd47, %fd49;
div.rn.f64 %fd483, %fd270, %fd271;
bra.uni $L__BB8_31;

$L__BB8_29:
sub.f64 %fd483, %fd47, %fd49;

$L__BB8_31:
mul.f64 %fd272, %fd483, %fd483;
fma.rn.f64 %fd273, %fd483, %fd483, %fd272;
add.f64 %fd274, %fd48, %fd272;
div.rn.f64 %fd484, %fd273, %fd274;

$L__BB8_32:
sub.f64 %fd284, %fd200, %fd484;
mul.f64 %fd285, %fd47, %fd284;
div.rn.f64 %fd286, %fd484, %fd483;
mul.f64 %fd287, %fd48, %fd286;
sub.f64 %fd56, %fd285, %fd287;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+40], %fd56;
mul.f64 %fd517, %fd22, %fd22;
mul.f64 %fd288, %fd45, %fd45;
fma.rn.f64 %fd506, %fd25, %fd25, %fd288;
mul.f64 %fd289, %fd45, %fd46;
fma.rn.f64 %fd487, %fd25, %fd26, %fd289;
mul.f64 %fd290, %fd46, %fd46;
fma.rn.f64 %fd291, %fd26, %fd26, %fd290;
fma.rn.f64 %fd507, %fd56, %fd56, %fd291;
mul.f64 %fd485, %fd22, %fd25;
mul.f64 %fd292, %fd485, %fd485;
mul.f64 %fd486, %fd22, %fd26;
fma.rn.f64 %fd293, %fd486, %fd486, %fd292;
fma.rn.f64 %fd294, %fd487, %fd487, %fd293;
add.f64 %fd295, %fd294, %fd294;
sqrt.rn.f64 %fd296, %fd295;
setp.ltu.f64 %p24, %fd296, 0d3D719799812DEA11;
mov.f64 %fd508, %fd200;
mov.f64 %fd509, %fd182;
mov.f64 %fd510, %fd182;
mov.f64 %fd511, %fd182;
mov.f64 %fd512, %fd200;
mov.f64 %fd513, %fd182;
mov.f64 %fd514, %fd182;
mov.f64 %fd515, %fd182;
mov.f64 %fd516, %fd200;
@%p24 bra $L__BB8_41;

mov.u32 %r120, 0;
mov.f64 %fd516, %fd200;
mov.f64 %fd515, %fd182;
mov.f64 %fd514, %fd182;
mov.f64 %fd513, %fd182;
mov.f64 %fd512, %fd200;
mov.f64 %fd511, %fd182;
mov.f64 %fd510, %fd182;
mov.f64 %fd509, %fd182;
mov.f64 %fd508, %fd200;

$L__BB8_34:
setp.eq.f64 %p25, %fd485, 0d0000000000000000;
mov.f64 %fd500, %fd200;
mov.f64 %fd501, %fd182;
@%p25 bra $L__BB8_36;

sub.f64 %fd308, %fd506, %fd517;
add.f64 %fd309, %fd485, %fd485;
div.rn.f64 %fd310, %fd308, %fd309;
setp.lt.f64 %p26, %fd310, 0d0000000000000000;
selp.f64 %fd311, 0dBFF0000000000000, 0d3FF0000000000000, %p26;
fma.rn.f64 %fd312, %fd310, %fd310, 0d3FF0000000000000;
sqrt.rn.f64 %fd313, %fd312;
fma.rn.f64 %fd314, %fd310, %fd311, %fd313;
div.rn.f64 %fd315, %fd311, %fd314;
fma.rn.f64 %fd316, %fd315, %fd315, 0d3FF0000000000000;
sqrt.rn.f64 %fd317, %fd316;
rcp.rn.f64 %fd500, %fd317;
mul.f64 %fd501, %fd315, %fd500;

$L__BB8_36:
mul.f64 %fd320, %fd485, %fd501;
mul.f64 %fd321, %fd517, %fd500;
sub.f64 %fd322, %fd321, %fd320;
mul.f64 %fd323, %fd485, %fd500;
fma.rn.f64 %fd324, %fd517, %fd501, %fd323;
mul.f64 %fd325, %fd506, %fd501;
sub.f64 %fd326, %fd323, %fd325;
fma.rn.f64 %fd327, %fd506, %fd500, %fd320;
mul.f64 %fd328, %fd500, %fd322;
mul.f64 %fd329, %fd501, %fd326;
sub.f64 %fd82, %fd328, %fd329;
mul.f64 %fd330, %fd500, %fd324;
mul.f64 %fd331, %fd501, %fd327;
sub.f64 %fd83, %fd330, %fd331;
mul.f64 %fd332, %fd500, %fd327;
fma.rn.f64 %fd84, %fd501, %fd324, %fd332;
mul.f64 %fd333, %fd487, %fd501;
mul.f64 %fd334, %fd486, %fd500;
sub.f64 %fd85, %fd334, %fd333;
mul.f64 %fd335, %fd486, %fd501;
fma.rn.f64 %fd86, %fd487, %fd500, %fd335;
mul.f64 %fd336, %fd509, %fd501;
mul.f64 %fd337, %fd508, %fd500;
sub.f64 %fd87, %fd337, %fd336;
mul.f64 %fd338, %fd508, %fd501;
fma.rn.f64 %fd88, %fd509, %fd500, %fd338;
mul.f64 %fd339, %fd512, %fd501;
mul.f64 %fd340, %fd511, %fd500;
sub.f64 %fd89, %fd340, %fd339;
mul.f64 %fd341, %fd511, %fd501;
fma.rn.f64 %fd90, %fd512, %fd500, %fd341;
mul.f64 %fd342, %fd515, %fd501;
mul.f64 %fd343, %fd514, %fd500;
sub.f64 %fd91, %fd343, %fd342;
mul.f64 %fd344, %fd514, %fd501;
fma.rn.f64 %fd92, %fd515, %fd500, %fd344;
setp.eq.f64 %p27, %fd85, 0d0000000000000000;
mov.f64 %fd502, %fd200;
mov.f64 %fd503, %fd182;
@%p27 bra $L__BB8_38;

sub.f64 %fd345, %fd507, %fd82;
add.f64 %fd346, %fd85, %fd85;
div.rn.f64 %fd347, %fd345, %fd346;
setp.lt.f64 %p28, %fd347, 0d0000000000000000;
selp.f64 %fd348, 0dBFF0000000000000, 0d3FF0000000000000, %p28;
fma.rn.f64 %fd349, %fd347, %fd347, 0d3FF0000000000000;
sqrt.rn.f64 %fd350, %fd349;
fma.rn.f64 %fd351, %fd347, %fd348, %fd350;
div.rn.f64 %fd352, %fd348, %fd351;
fma.rn.f64 %fd353, %fd352, %fd352, 0d3FF0000000000000;
sqrt.rn.f64 %fd354, %fd353;
rcp.rn.f64 %fd502, %fd354;
mul.f64 %fd503, %fd352, %fd502;

$L__BB8_38:
mul.f64 %fd357, %fd85, %fd503;
mul.f64 %fd358, %fd82, %fd502;
sub.f64 %fd359, %fd358, %fd357;
mul.f64 %fd360, %fd86, %fd503;
mul.f64 %fd361, %fd83, %fd502;
sub.f64 %fd97, %fd361, %fd360;
mul.f64 %fd362, %fd85, %fd502;
fma.rn.f64 %fd363, %fd82, %fd503, %fd362;
mul.f64 %fd364, %fd507, %fd503;
sub.f64 %fd365, %fd362, %fd364;
fma.rn.f64 %fd366, %fd507, %fd502, %fd357;
mul.f64 %fd367, %fd502, %fd359;
mul.f64 %fd368, %fd503, %fd365;
sub.f64 %fd517, %fd367, %fd368;
mul.f64 %fd369, %fd83, %fd503;
fma.rn.f64 %fd99, %fd86, %fd502, %fd369;
mul.f64 %fd370, %fd502, %fd363;
mul.f64 %fd371, %fd503, %fd366;
sub.f64 %fd100, %fd370, %fd371;
mul.f64 %fd372, %fd502, %fd366;
fma.rn.f64 %fd101, %fd503, %fd363, %fd372;
mul.f64 %fd373, %fd510, %fd503;
mul.f64 %fd374, %fd87, %fd502;
sub.f64 %fd508, %fd374, %fd373;
mul.f64 %fd375, %fd87, %fd503;
fma.rn.f64 %fd103, %fd510, %fd502, %fd375;
mul.f64 %fd376, %fd513, %fd503;
mul.f64 %fd377, %fd89, %fd502;
sub.f64 %fd511, %fd377, %fd376;
mul.f64 %fd378, %fd89, %fd503;
fma.rn.f64 %fd105, %fd513, %fd502, %fd378;
mul.f64 %fd379, %fd516, %fd503;
mul.f64 %fd380, %fd91, %fd502;
sub.f64 %fd514, %fd380, %fd379;
mul.f64 %fd381, %fd91, %fd503;
fma.rn.f64 %fd107, %fd516, %fd502, %fd381;
setp.eq.f64 %p29, %fd99, 0d0000000000000000;
mov.f64 %fd504, %fd200;
mov.f64 %fd505, %fd182;
@%p29 bra $L__BB8_40;

sub.f64 %fd382, %fd101, %fd84;
add.f64 %fd383, %fd99, %fd99;
div.rn.f64 %fd384, %fd382, %fd383;
setp.lt.f64 %p30, %fd384, 0d0000000000000000;
selp.f64 %fd385, 0dBFF0000000000000, 0d3FF0000000000000, %p30;
fma.rn.f64 %fd386, %fd384, %fd384, 0d3FF0000000000000;
sqrt.rn.f64 %fd387, %fd386;
fma.rn.f64 %fd388, %fd384, %fd385, %fd387;
div.rn.f64 %fd389, %fd385, %fd388;
fma.rn.f64 %fd390, %fd389, %fd389, 0d3FF0000000000000;
sqrt.rn.f64 %fd391, %fd390;
rcp.rn.f64 %fd504, %fd391;
mul.f64 %fd505, %fd389, %fd504;

$L__BB8_40:
mul.f64 %fd392, %fd97, %fd505;
fma.rn.f64 %fd486, %fd100, %fd504, %fd392;
mul.f64 %fd393, %fd99, %fd505;
mul.f64 %fd394, %fd84, %fd504;
sub.f64 %fd395, %fd394, %fd393;
mul.f64 %fd396, %fd99, %fd504;
fma.rn.f64 %fd397, %fd84, %fd505, %fd396;
mul.f64 %fd398, %fd101, %fd505;
sub.f64 %fd399, %fd396, %fd398;
fma.rn.f64 %fd400, %fd101, %fd504, %fd393;
mul.f64 %fd401, %fd100, %fd505;
mul.f64 %fd402, %fd97, %fd504;
sub.f64 %fd485, %fd402, %fd401;
mul.f64 %fd403, %fd504, %fd395;
mul.f64 %fd404, %fd505, %fd399;
sub.f64 %fd506, %fd403, %fd404;
mul.f64 %fd405, %fd504, %fd397;
mul.f64 %fd406, %fd505, %fd400;
sub.f64 %fd487, %fd405, %fd406;
mul.f64 %fd407, %fd504, %fd400;
fma.rn.f64 %fd507, %fd505, %fd397, %fd407;
mul.f64 %fd408, %fd103, %fd505;
mul.f64 %fd409, %fd88, %fd504;
sub.f64 %fd509, %fd409, %fd408;
mul.f64 %fd410, %fd88, %fd505;
fma.rn.f64 %fd510, %fd103, %fd504, %fd410;
mul.f64 %fd411, %fd105, %fd505;
mul.f64 %fd412, %fd90, %fd504;
sub.f64 %fd512, %fd412, %fd411;
mul.f64 %fd413, %fd90, %fd505;
fma.rn.f64 %fd513, %fd105, %fd504, %fd413;
mul.f64 %fd414, %fd107, %fd505;
mul.f64 %fd415, %fd92, %fd504;
sub.f64 %fd515, %fd415, %fd414;
mul.f64 %fd416, %fd92, %fd505;
fma.rn.f64 %fd516, %fd107, %fd504, %fd416;
mul.f64 %fd417, %fd485, %fd485;
fma.rn.f64 %fd418, %fd486, %fd486, %fd417;
fma.rn.f64 %fd419, %fd487, %fd487, %fd418;
add.f64 %fd420, %fd419, %fd419;
sqrt.rn.f64 %fd421, %fd420;
setp.ge.f64 %p31, %fd421, 0d3D719799812DEA11;
add.s32 %r120, %r120, 1;
setp.lt.u32 %p32, %r120, 16;
and.pred %p33, %p32, %p31;
@%p33 bra $L__BB8_34;

$L__BB8_41:
setp.geu.f64 %p34, %fd517, %fd506;
mov.f64 %fd518, %fd506;
mov.f64 %fd519, %fd508;
mov.f64 %fd521, %fd511;
mov.f64 %fd523, %fd514;
@%p34 bra $L__BB8_43;

mov.f64 %fd518, %fd517;
mov.f64 %fd519, %fd509;
mov.f64 %fd509, %fd508;
mov.f64 %fd521, %fd512;
mov.f64 %fd512, %fd511;
mov.f64 %fd523, %fd515;
mov.f64 %fd515, %fd514;
mov.f64 %fd517, %fd506;

$L__BB8_43:
setp.geu.f64 %p35, %fd517, %fd507;
mov.f64 %fd535, %fd507;
mov.f64 %fd527, %fd519;
mov.f64 %fd529, %fd521;
mov.f64 %fd531, %fd523;
@%p35 bra $L__BB8_45;

mov.f64 %fd535, %fd517;
mov.f64 %fd527, %fd510;
mov.f64 %fd510, %fd519;
mov.f64 %fd529, %fd513;
mov.f64 %fd513, %fd521;
mov.f64 %fd531, %fd516;
mov.f64 %fd516, %fd523;
mov.f64 %fd517, %fd507;

$L__BB8_45:
setp.geu.f64 %p36, %fd518, %fd535;
mov.f64 %fd534, %fd518;
mov.f64 %fd536, %fd509;
mov.f64 %fd538, %fd512;
mov.f64 %fd540, %fd515;
@%p36 bra $L__BB8_47;

mov.f64 %fd534, %fd535;
mov.f64 %fd535, %fd518;
mov.f64 %fd536, %fd510;
mov.f64 %fd510, %fd509;
mov.f64 %fd538, %fd513;
mov.f64 %fd513, %fd512;
mov.f64 %fd540, %fd516;
mov.f64 %fd516, %fd515;

$L__BB8_47:
abs.f64 %fd423, %fd517;
setp.lt.f64 %p37, %fd423, 0d3D719799812DEA11;
mov.f64 %fd544, 0d0000000000000000;
mov.f64 %fd542, %fd544;
@%p37 bra $L__BB8_49;

rcp.rn.f64 %fd542, %fd517;

$L__BB8_49:
abs.f64 %fd425, %fd534;
setp.lt.f64 %p38, %fd425, 0d3D719799812DEA11;
mov.f64 %fd543, %fd544;
@%p38 bra $L__BB8_51;

rcp.rn.f64 %fd543, %fd534;

$L__BB8_51:
abs.f64 %fd427, %fd535;
setp.lt.f64 %p39, %fd427, 0d3D719799812DEA11;
@%p39 bra $L__BB8_53;

rcp.rn.f64 %fd544, %fd535;

$L__BB8_53:
mul.f64 %fd428, %fd527, %fd542;
mul.f64 %fd429, %fd536, %fd543;
mul.f64 %fd430, %fd536, %fd429;
fma.rn.f64 %fd431, %fd527, %fd428, %fd430;
mul.f64 %fd432, %fd510, %fd544;
fma.rn.f64 %fd433, %fd510, %fd432, %fd431;
mul.f64 %fd434, %fd538, %fd429;
fma.rn.f64 %fd435, %fd529, %fd428, %fd434;
fma.rn.f64 %fd436, %fd513, %fd432, %fd435;
mul.f64 %fd437, %fd540, %fd429;
fma.rn.f64 %fd438, %fd531, %fd428, %fd437;
fma.rn.f64 %fd439, %fd516, %fd432, %fd438;
mul.f64 %fd440, %fd529, %fd542;
mul.f64 %fd441, %fd538, %fd543;
mul.f64 %fd442, %fd538, %fd441;
fma.rn.f64 %fd443, %fd529, %fd440, %fd442;
mul.f64 %fd444, %fd513, %fd544;
fma.rn.f64 %fd445, %fd513, %fd444, %fd443;
mul.f64 %fd446, %fd540, %fd441;
fma.rn.f64 %fd447, %fd531, %fd440, %fd446;
fma.rn.f64 %fd448, %fd516, %fd444, %fd447;
mul.f64 %fd449, %fd531, %fd542;
mul.f64 %fd450, %fd540, %fd543;
mul.f64 %fd451, %fd540, %fd450;
fma.rn.f64 %fd452, %fd531, %fd449, %fd451;
mul.f64 %fd453, %fd516, %fd544;
fma.rn.f64 %fd454, %fd516, %fd453, %fd452;
mul.f64 %fd455, %fd25, %fd436;
fma.rn.f64 %fd456, %fd22, %fd433, %fd455;
fma.rn.f64 %fd457, %fd26, %fd439, %fd456;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+48], %fd457;
mul.f64 %fd458, %fd46, %fd439;
fma.rn.f64 %fd459, %fd45, %fd436, %fd458;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+56], %fd459;
mul.f64 %fd460, %fd56, %fd439;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+64], %fd460;
mul.f64 %fd461, %fd46, %fd448;
fma.rn.f64 %fd462, %fd45, %fd445, %fd461;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+72], %fd462;
mul.f64 %fd463, %fd56, %fd448;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+80], %fd463;
mul.f64 %fd464, %fd56, %fd454;
st.shared.f64 [_ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds+88], %fd464;

$L__BB8_54:
mov.u32 %r109, %tid.x;
setp.gt.u32 %p40, %r109, 11;
bar.sync 0;
@%p40 bra $L__BB8_57;

ld.param.u64 %rd14, [_Z18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPd_param_5];
mov.u32 %r111, %tid.x;
mov.u32 %r110, _ZZ18prepare_svd_kernelILi256E10PayoffCallEviiT0_PKdPiPdE9smem_svds;
shl.b32 %r101, %r111, 3;
add.s32 %r103, %r110, %r101;
ld.shared.f64 %fd465, [%r103];
mov.u32 %r104, %ctaid.x;
shl.b32 %r105, %r104, 4;
add.s32 %r106, %r105, %r111;
cvta.to.global.u64 %rd8, %rd14;
mul.wide.u32 %rd9, %r106, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd465;

$L__BB8_57:
ret;

}

.visible .entry _Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd(
.param .u32 _Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_0,
.param .align 8 .b8 _Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_1[8],
.param .u64 _Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_2,
.param .u64 _Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_3,
.param .u64 _Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_4,
.param .u64 _Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_5,
.param .u64 _Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_6
)
.maxntid 128, 1, 1
.minnctapersm 8
{
.reg .pred %p<18>;
.reg .b32 %r<49>;
.reg .f64 %fd<183>;
.reg .b64 %rd<51>;

	.shared .align 8 .b8 _ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE5lsums[24];

	.shared .align 8 .b8 _ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd[96];

ld.param.f64 %fd79, [_Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_1];
ld.param.u32 %r14, [_Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_0];
ld.param.u64 %rd16, [_Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_2];
ld.param.u64 %rd17, [_Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_3];
ld.param.u64 %rd18, [_Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_4];
ld.param.u64 %rd20, [_Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_5];
cvta.to.global.u64 %rd21, %rd20;
ld.global.nc.u32 %r15, [%rd21];
setp.ne.s32 %p1, %r15, 0;
@%p1 bra $L__BB9_30;

mov.u32 %r1, %tid.x;
setp.gt.u32 %p2, %r1, 11;
@%p2 bra $L__BB9_3;

cvta.to.global.u64 %rd22, %rd16;
mul.wide.u32 %rd23, %r1, 8;
add.s64 %rd24, %rd22, %rd23;
ld.global.nc.f64 %fd80, [%rd24];
shl.b32 %r16, %r1, 3;
mov.u32 %r17, _ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd;
add.s32 %r18, %r17, %r16;
st.shared.f64 [%r18], %fd80;

$L__BB9_3:
bar.sync 0;
ld.shared.f64 %fd1, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+8];
ld.shared.f64 %fd2, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+16];
ld.shared.f64 %fd3, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+24];
ld.shared.f64 %fd4, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+32];
ld.shared.f64 %fd5, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+40];
ld.shared.f64 %fd6, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+48];
ld.shared.f64 %fd7, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+56];
ld.shared.f64 %fd8, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+64];
ld.shared.f64 %fd9, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+72];
ld.shared.f64 %fd10, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+80];
ld.shared.f64 %fd11, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd+88];
ld.shared.f64 %fd12, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE10shared_svd];
setp.eq.f64 %p3, %fd12, 0d0000000000000000;
mov.f64 %fd180, 0d0000000000000000;
mov.f64 %fd160, %fd180;
@%p3 bra $L__BB9_5;

rcp.rn.f64 %fd160, %fd12;

$L__BB9_5:
setp.eq.f64 %p4, %fd3, 0d0000000000000000;
mov.f64 %fd161, %fd180;
@%p4 bra $L__BB9_7;

rcp.rn.f64 %fd161, %fd3;

$L__BB9_7:
setp.eq.f64 %p5, %fd5, 0d0000000000000000;
mov.f64 %fd162, %fd180;
@%p5 bra $L__BB9_9;

rcp.rn.f64 %fd162, %fd5;

$L__BB9_9:
mul.f64 %fd87, %fd160, %fd161;
mul.f64 %fd19, %fd1, %fd87;
mul.f64 %fd88, %fd160, %fd162;
mul.f64 %fd20, %fd2, %fd88;
mul.f64 %fd21, %fd4, %fd162;
mul.f64 %fd22, %fd6, %fd160;
mov.u32 %r19, %ctaid.x;
shl.b32 %r2, %r19, 7;
add.s32 %r47, %r2, %r1;
setp.ge.s32 %p6, %r47, %r14;
mov.f64 %fd181, %fd180;
mov.f64 %fd182, %fd180;
@%p6 bra $L__BB9_26;

not.b32 %r20, %r1;
add.s32 %r21, %r20, %r14;
sub.s32 %r22, %r21, %r2;
mov.u32 %r23, %nctaid.x;
shl.b32 %r24, %r23, 7;
div.u32 %r4, %r22, %r24;
add.s32 %r25, %r4, 1;
and.b32 %r46, %r25, 3;
setp.eq.s32 %p7, %r46, 0;
mov.f64 %fd91, 0d0000000000000000;
mov.f64 %fd182, %fd91;
mov.f64 %fd181, %fd91;
mov.f64 %fd180, %fd91;
@%p7 bra $L__BB9_15;

cvta.to.global.u64 %rd25, %rd18;
mul.wide.s32 %rd26, %r47, 8;
add.s64 %rd50, %rd25, %rd26;
cvta.to.global.u64 %rd27, %rd17;
add.s64 %rd49, %rd27, %rd26;

$L__BB9_12:
.pragma "nounroll";
ld.global.nc.f64 %fd97, [%rd49];
setp.geu.f64 %p8, %fd79, %fd97;
mul.f64 %fd98, %fd161, %fd97;
sub.f64 %fd99, %fd98, %fd19;
mul.f64 %fd100, %fd162, %fd97;
mul.f64 %fd101, %fd97, %fd100;
sub.f64 %fd102, %fd101, %fd20;
mul.f64 %fd103, %fd21, %fd99;
sub.f64 %fd27, %fd102, %fd103;
fma.rn.f64 %fd104, %fd7, %fd99, %fd22;
fma.rn.f64 %fd28, %fd8, %fd27, %fd104;
mul.f64 %fd105, %fd10, %fd27;
fma.rn.f64 %fd29, %fd9, %fd99, %fd105;
mov.f64 %fd166, %fd91;
@%p8 bra $L__BB9_14;

ld.global.nc.f64 %fd166, [%rd50];

$L__BB9_14:
fma.rn.f64 %fd180, %fd28, %fd166, %fd180;
fma.rn.f64 %fd181, %fd29, %fd166, %fd181;
mul.f64 %fd106, %fd11, %fd27;
fma.rn.f64 %fd182, %fd106, %fd166, %fd182;
add.s32 %r47, %r47, %r24;
mul.wide.s32 %rd28, %r24, 8;
add.s64 %rd50, %rd50, %rd28;
add.s64 %rd49, %rd49, %rd28;
add.s32 %r46, %r46, -1;
setp.ne.s32 %p9, %r46, 0;
@%p9 bra $L__BB9_12;

$L__BB9_15:
setp.lt.u32 %p10, %r4, 3;
@%p10 bra $L__BB9_26;

ld.param.u64 %rd47, [_Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_3];
mul.wide.s32 %rd7, %r24, 8;
cvta.to.global.u64 %rd8, %rd47;

$L__BB9_17:
cvt.s64.s32 %rd9, %r47;
mul.wide.s32 %rd29, %r47, 8;
add.s64 %rd10, %rd8, %rd29;
ld.global.nc.f64 %fd108, [%rd10];
setp.geu.f64 %p11, %fd79, %fd108;
mul.f64 %fd109, %fd161, %fd108;
sub.f64 %fd110, %fd109, %fd19;
mul.f64 %fd111, %fd162, %fd108;
mul.f64 %fd112, %fd108, %fd111;
sub.f64 %fd113, %fd112, %fd20;
mul.f64 %fd114, %fd21, %fd110;
sub.f64 %fd44, %fd113, %fd114;
fma.rn.f64 %fd115, %fd7, %fd110, %fd22;
fma.rn.f64 %fd45, %fd8, %fd44, %fd115;
mul.f64 %fd116, %fd10, %fd44;
fma.rn.f64 %fd46, %fd9, %fd110, %fd116;
mov.f64 %fd176, 0d0000000000000000;
@%p11 bra $L__BB9_19;

cvta.to.global.u64 %rd30, %rd18;
shl.b64 %rd31, %rd9, 3;
add.s64 %rd32, %rd30, %rd31;
ld.global.nc.f64 %fd176, [%rd32];

$L__BB9_19:
mov.f64 %fd177, 0d0000000000000000;
fma.rn.f64 %fd49, %fd45, %fd176, %fd180;
fma.rn.f64 %fd50, %fd46, %fd176, %fd181;
mul.f64 %fd118, %fd11, %fd44;
fma.rn.f64 %fd51, %fd118, %fd176, %fd182;
cvt.u32.u64 %r29, %rd9;
add.s32 %r30, %r29, %r24;
cvt.s64.s32 %rd11, %r30;
add.s64 %rd12, %rd10, %rd7;
ld.global.nc.f64 %fd119, [%rd12];
setp.geu.f64 %p12, %fd79, %fd119;
mul.f64 %fd120, %fd161, %fd119;
sub.f64 %fd121, %fd120, %fd19;
mul.f64 %fd122, %fd162, %fd119;
mul.f64 %fd123, %fd119, %fd122;
sub.f64 %fd124, %fd123, %fd20;
mul.f64 %fd125, %fd21, %fd121;
sub.f64 %fd52, %fd124, %fd125;
fma.rn.f64 %fd126, %fd7, %fd121, %fd22;
fma.rn.f64 %fd53, %fd8, %fd52, %fd126;
mul.f64 %fd127, %fd10, %fd52;
fma.rn.f64 %fd54, %fd9, %fd121, %fd127;
@%p12 bra $L__BB9_21;

cvta.to.global.u64 %rd33, %rd18;
shl.b64 %rd34, %rd11, 3;
add.s64 %rd35, %rd33, %rd34;
ld.global.nc.f64 %fd177, [%rd35];

$L__BB9_21:
mov.f64 %fd178, 0d0000000000000000;
fma.rn.f64 %fd57, %fd53, %fd177, %fd49;
fma.rn.f64 %fd58, %fd54, %fd177, %fd50;
mul.f64 %fd129, %fd11, %fd52;
fma.rn.f64 %fd59, %fd129, %fd177, %fd51;
cvt.u32.u64 %r31, %rd11;
add.s32 %r32, %r31, %r24;
cvt.s64.s32 %rd13, %r32;
add.s64 %rd14, %rd12, %rd7;
ld.global.nc.f64 %fd130, [%rd14];
setp.geu.f64 %p13, %fd79, %fd130;
mul.f64 %fd131, %fd161, %fd130;
sub.f64 %fd132, %fd131, %fd19;
mul.f64 %fd133, %fd162, %fd130;
mul.f64 %fd134, %fd130, %fd133;
sub.f64 %fd135, %fd134, %fd20;
mul.f64 %fd136, %fd21, %fd132;
sub.f64 %fd60, %fd135, %fd136;
fma.rn.f64 %fd137, %fd7, %fd132, %fd22;
fma.rn.f64 %fd61, %fd8, %fd60, %fd137;
mul.f64 %fd138, %fd10, %fd60;
fma.rn.f64 %fd62, %fd9, %fd132, %fd138;
@%p13 bra $L__BB9_23;

cvta.to.global.u64 %rd36, %rd18;
shl.b64 %rd37, %rd13, 3;
add.s64 %rd38, %rd36, %rd37;
ld.global.nc.f64 %fd178, [%rd38];

$L__BB9_23:
mov.f64 %fd179, 0d0000000000000000;
fma.rn.f64 %fd65, %fd61, %fd178, %fd57;
fma.rn.f64 %fd66, %fd62, %fd178, %fd58;
mul.f64 %fd140, %fd11, %fd60;
fma.rn.f64 %fd67, %fd140, %fd178, %fd59;
cvt.u32.u64 %r33, %rd13;
add.s32 %r34, %r33, %r24;
cvt.s64.s32 %rd15, %r34;
add.s64 %rd39, %rd14, %rd7;
ld.global.nc.f64 %fd141, [%rd39];
setp.geu.f64 %p14, %fd79, %fd141;
mul.f64 %fd142, %fd161, %fd141;
sub.f64 %fd143, %fd142, %fd19;
mul.f64 %fd144, %fd162, %fd141;
mul.f64 %fd145, %fd141, %fd144;
sub.f64 %fd146, %fd145, %fd20;
mul.f64 %fd147, %fd21, %fd143;
sub.f64 %fd68, %fd146, %fd147;
fma.rn.f64 %fd148, %fd7, %fd143, %fd22;
fma.rn.f64 %fd69, %fd8, %fd68, %fd148;
mul.f64 %fd149, %fd10, %fd68;
fma.rn.f64 %fd70, %fd9, %fd143, %fd149;
@%p14 bra $L__BB9_25;

cvta.to.global.u64 %rd40, %rd18;
shl.b64 %rd41, %rd15, 3;
add.s64 %rd42, %rd40, %rd41;
ld.global.nc.f64 %fd179, [%rd42];

$L__BB9_25:
ld.param.u32 %r44, [_Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_0];
fma.rn.f64 %fd180, %fd69, %fd179, %fd65;
fma.rn.f64 %fd181, %fd70, %fd179, %fd66;
mul.f64 %fd150, %fd11, %fd68;
fma.rn.f64 %fd182, %fd150, %fd179, %fd67;
cvt.u32.u64 %r35, %rd15;
add.s32 %r47, %r35, %r24;
setp.lt.s32 %p15, %r47, %r44;
@%p15 bra $L__BB9_17;

$L__BB9_26:
mov.u32 %r42, %tid.x;
setp.ne.s32 %p16, %r42, 0;
@%p16 bra $L__BB9_28;

mov.u64 %rd43, 0;
st.shared.u64 [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE5lsums], %rd43;
st.shared.u64 [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE5lsums+8], %rd43;
st.shared.u64 [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE5lsums+16], %rd43;

$L__BB9_28:
bar.sync 0;
mov.u32 %r38, _ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE5lsums;
atom.shared.add.f64 %fd151, [%r38], %fd180;
add.s32 %r39, %r38, 8;
atom.shared.add.f64 %fd152, [%r39], %fd181;
add.s32 %r40, %r38, 16;
atom.shared.add.f64 %fd153, [%r40], %fd182;
bar.sync 0;
@%p16 bra $L__BB9_30;

mov.u32 %r43, %ctaid.x;
ld.param.u64 %rd48, [_Z27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPd_param_6];
ld.shared.f64 %fd154, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE5lsums];
cvta.to.global.u64 %rd44, %rd48;
mul.wide.u32 %rd45, %r43, 8;
add.s64 %rd46, %rd44, %rd45;
st.global.f64 [%rd46], %fd154;
ld.shared.f64 %fd155, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE5lsums+8];
st.global.f64 [%rd46+1024], %fd155;
ld.shared.f64 %fd156, [_ZZ27compute_partial_beta_kernelILi128E10PayoffCallEviT0_PKdS3_S3_PKiPdE5lsums+16];
st.global.f64 [%rd46+2048], %fd156;

$L__BB9_30:
ret;

}

.visible .entry _Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd(
.param .u32 _Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_0,
.param .align 8 .b8 _Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_1[8],
.param .f64 _Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_2,
.param .u64 _Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_3,
.param .u64 _Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_4,
.param .u64 _Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_5,
.param .u64 _Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_6
)
.maxntid 128, 1, 1
{
.reg .pred %p<26>;
.reg .b32 %r<59>;
.reg .f64 %fd<69>;
.reg .b64 %rd<45>;


ld.param.f64 %fd5, [_Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_1];
ld.param.u32 %r24, [_Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_0];
ld.param.f64 %fd6, [_Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_2];
ld.param.u64 %rd19, [_Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_3];
ld.param.u64 %rd16, [_Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_4];
ld.param.u64 %rd17, [_Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_5];
ld.param.u64 %rd18, [_Z22update_cashflow_kernelILi128E10PayoffCallEviT0_dPKdS3_PKiPd_param_6];
cvta.to.global.u64 %rd20, %rd19;
mov.u32 %r25, %nctaid.x;
shl.b32 %r1, %r25, 7;
ld.global.nc.f64 %fd1, [%rd20];
ld.global.nc.f64 %fd2, [%rd20+8];
ld.global.nc.f64 %fd3, [%rd20+16];
mov.u32 %r26, %ctaid.x;
shl.b32 %r2, %r26, 7;
mov.u32 %r3, %tid.x;
add.s32 %r53, %r2, %r3;
setp.ge.s32 %p1, %r53, %r24;
@%p1 bra $L__BB10_14;

cvta.to.global.u64 %rd21, %rd17;
ld.global.nc.u32 %r28, [%rd21];
setp.eq.s32 %p2, %r28, 0;
not.b32 %r29, %r3;
add.s32 %r30, %r29, %r24;
sub.s32 %r31, %r30, %r2;
div.u32 %r4, %r31, %r1;
add.s32 %r32, %r4, 1;
and.b32 %r52, %r32, 3;
@%p2 bra $L__BB10_8;

setp.eq.s32 %p3, %r52, 0;
@%p3 bra $L__BB10_5;

add.s32 %r53, %r2, %r3;
cvta.to.global.u64 %rd22, %rd18;
mul.wide.s32 %rd23, %r53, 8;
add.s64 %rd42, %rd22, %rd23;
mul.wide.s32 %rd2, %r1, 8;

$L__BB10_4:
.pragma "nounroll";
ld.global.f64 %fd7, [%rd42];
mul.f64 %fd8, %fd7, %fd6;
st.global.f64 [%rd42], %fd8;
add.s32 %r53, %r53, %r1;
add.s64 %rd42, %rd42, %rd2;
add.s32 %r52, %r52, -1;
setp.ne.s32 %p4, %r52, 0;
@%p4 bra $L__BB10_4;

$L__BB10_5:
setp.lt.u32 %p5, %r4, 3;
@%p5 bra $L__BB10_14;

mul.wide.s32 %rd5, %r1, 8;
cvta.to.global.u64 %rd6, %rd18;

$L__BB10_7:
mul.wide.s32 %rd24, %r53, 8;
add.s64 %rd25, %rd6, %rd24;
ld.global.f64 %fd9, [%rd25];
mul.f64 %fd10, %fd9, %fd6;
st.global.f64 [%rd25], %fd10;
add.s64 %rd26, %rd25, %rd5;
ld.global.f64 %fd11, [%rd26];
mul.f64 %fd12, %fd11, %fd6;
st.global.f64 [%rd26], %fd12;
add.s32 %r39, %r53, %r1;
add.s32 %r40, %r39, %r1;
add.s64 %rd27, %rd26, %rd5;
ld.global.f64 %fd13, [%rd27];
mul.f64 %fd14, %fd13, %fd6;
st.global.f64 [%rd27], %fd14;
add.s32 %r41, %r40, %r1;
add.s64 %rd28, %rd27, %rd5;
ld.global.f64 %fd15, [%rd28];
mul.f64 %fd16, %fd15, %fd6;
st.global.f64 [%rd28], %fd16;
add.s32 %r53, %r41, %r1;
setp.lt.s32 %p6, %r53, %r24;
@%p6 bra $L__BB10_7;
bra.uni $L__BB10_14;

$L__BB10_8:
setp.eq.s32 %p7, %r52, 0;
add.s32 %r57, %r2, %r3;
@%p7 bra $L__BB10_11;

add.s32 %r57, %r2, %r3;
cvta.to.global.u64 %rd29, %rd16;
mul.wide.s32 %rd30, %r57, 8;
add.s64 %rd44, %rd29, %rd30;
mul.wide.s32 %rd8, %r1, 8;
cvta.to.global.u64 %rd31, %rd18;
add.s64 %rd43, %rd31, %rd30;
mov.f64 %fd22, 0d0000000000000000;

$L__BB10_10:
.pragma "nounroll";
ld.global.f64 %fd17, [%rd43];
mul.f64 %fd18, %fd17, %fd6;
ld.global.nc.f64 %fd19, [%rd44];
mul.f64 %fd20, %fd19, %fd19;
sub.f64 %fd21, %fd19, %fd5;
max.f64 %fd23, %fd21, %fd22;
fma.rn.f64 %fd24, %fd2, %fd19, %fd1;
fma.rn.f64 %fd25, %fd3, %fd20, %fd24;
mul.f64 %fd26, %fd25, %fd6;
setp.le.f64 %p8, %fd23, 0d3E45798EE2308C3A;
setp.le.f64 %p9, %fd23, %fd26;
or.pred %p10, %p8, %p9;
selp.f64 %fd27, %fd18, %fd23, %p10;
st.global.f64 [%rd43], %fd27;
add.s32 %r57, %r57, %r1;
add.s64 %rd44, %rd44, %rd8;
add.s64 %rd43, %rd43, %rd8;
add.s32 %r52, %r52, -1;
setp.ne.s32 %p11, %r52, 0;
@%p11 bra $L__BB10_10;

$L__BB10_11:
setp.lt.u32 %p12, %r4, 3;
@%p12 bra $L__BB10_14;

mul.wide.s32 %rd14, %r1, 8;
cvta.to.global.u64 %rd15, %rd16;
cvta.to.global.u64 %rd32, %rd18;
mov.f64 %fd33, 0d0000000000000000;

$L__BB10_13:
mul.wide.s32 %rd33, %r57, 8;
add.s64 %rd34, %rd32, %rd33;
ld.global.f64 %fd28, [%rd34];
mul.f64 %fd29, %fd28, %fd6;
add.s64 %rd35, %rd15, %rd33;
ld.global.nc.f64 %fd30, [%rd35];
mul.f64 %fd31, %fd30, %fd30;
sub.f64 %fd32, %fd30, %fd5;
max.f64 %fd34, %fd32, %fd33;
fma.rn.f64 %fd35, %fd2, %fd30, %fd1;
fma.rn.f64 %fd36, %fd3, %fd31, %fd35;
mul.f64 %fd37, %fd36, %fd6;
setp.le.f64 %p13, %fd34, 0d3E45798EE2308C3A;
setp.le.f64 %p14, %fd34, %fd37;
or.pred %p15, %p13, %p14;
selp.f64 %fd38, %fd29, %fd34, %p15;
st.global.f64 [%rd34], %fd38;
add.s64 %rd36, %rd34, %rd14;
ld.global.f64 %fd39, [%rd36];
mul.f64 %fd40, %fd39, %fd6;
add.s64 %rd37, %rd35, %rd14;
ld.global.nc.f64 %fd41, [%rd37];
mul.f64 %fd42, %fd41, %fd41;
sub.f64 %fd43, %fd41, %fd5;
max.f64 %fd44, %fd43, %fd33;
fma.rn.f64 %fd45, %fd2, %fd41, %fd1;
fma.rn.f64 %fd46, %fd3, %fd42, %fd45;
mul.f64 %fd47, %fd46, %fd6;
setp.le.f64 %p16, %fd44, 0d3E45798EE2308C3A;
setp.le.f64 %p17, %fd44, %fd47;
or.pred %p18, %p16, %p17;
selp.f64 %fd48, %fd40, %fd44, %p18;
st.global.f64 [%rd36], %fd48;
add.s32 %r48, %r57, %r1;
add.s32 %r49, %r48, %r1;
add.s64 %rd38, %rd36, %rd14;
ld.global.f64 %fd49, [%rd38];
mul.f64 %fd50, %fd49, %fd6;
add.s64 %rd39, %rd37, %rd14;
ld.global.nc.f64 %fd51, [%rd39];
mul.f64 %fd52, %fd51, %fd51;
sub.f64 %fd53, %fd51, %fd5;
max.f64 %fd54, %fd53, %fd33;
fma.rn.f64 %fd55, %fd2, %fd51, %fd1;
fma.rn.f64 %fd56, %fd3, %fd52, %fd55;
mul.f64 %fd57, %fd56, %fd6;
setp.le.f64 %p19, %fd54, 0d3E45798EE2308C3A;
setp.le.f64 %p20, %fd54, %fd57;
or.pred %p21, %p19, %p20;
selp.f64 %fd58, %fd50, %fd54, %p21;
st.global.f64 [%rd38], %fd58;
add.s32 %r50, %r49, %r1;
add.s64 %rd40, %rd38, %rd14;
ld.global.f64 %fd59, [%rd40];
mul.f64 %fd60, %fd59, %fd6;
add.s64 %rd41, %rd39, %rd14;
ld.global.nc.f64 %fd61, [%rd41];
mul.f64 %fd62, %fd61, %fd61;
sub.f64 %fd63, %fd61, %fd5;
max.f64 %fd64, %fd63, %fd33;
fma.rn.f64 %fd65, %fd2, %fd61, %fd1;
fma.rn.f64 %fd66, %fd3, %fd62, %fd65;
mul.f64 %fd67, %fd66, %fd6;
setp.le.f64 %p22, %fd64, 0d3E45798EE2308C3A;
setp.le.f64 %p23, %fd64, %fd67;
or.pred %p24, %p22, %p23;
selp.f64 %fd68, %fd60, %fd64, %p24;
st.global.f64 [%rd40], %fd68;
add.s32 %r57, %r50, %r1;
setp.lt.s32 %p25, %r57, %r24;
@%p25 bra $L__BB10_13;

$L__BB10_14:
ret;

}

