.version 7.7
.target sm_80
.address_size 64


.extern .func __assertfail
(
.param .b64 __assertfail_param_0,
.param .b64 __assertfail_param_1,
.param .b32 __assertfail_param_2,
.param .b64 __assertfail_param_3,
.param .b64 __assertfail_param_4
)
;
.global .align 1 .b8 __unnamed_1[21] = {118, 111, 105, 100, 32, 116, 101, 115, 116, 75, 101, 114, 110, 101, 108, 40, 105, 110, 116, 41, 0};
.global .align 1 .b8 __unnamed_2[18] = {118, 111, 105, 100, 32, 112, 101, 114, 102, 75, 101, 114, 110, 101, 108, 40, 41, 0};
.global .align 1 .b8 __unnamed_3[19] = {118, 111, 105, 100, 32, 112, 101, 114, 102, 75, 101, 114, 110, 101, 108, 50, 40, 41, 0};
.global .align 1 .b8 $str[8] = {103, 105, 100, 32, 60, 32, 78, 0};
.global .align 1 .b8 $str$1[14] = {115, 114, 99, 47, 97, 115, 115, 101, 114, 116, 46, 99, 117, 0};
.global .align 1 .b8 $str$2[30] = {103, 105, 100, 32, 60, 61, 32, 98, 108, 111, 99, 107, 68, 105, 109, 46, 120, 32, 42, 32, 103, 114, 105, 100, 68, 105, 109, 46, 120, 0};
.global .align 1 .b8 $str$3[9] = {115, 32, 60, 61, 32, 103, 105, 100, 0};

.visible .entry _Z10testKerneli(
.param .u32 _Z10testKerneli_param_0
)
{
.reg .pred %p<2>;
.reg .b32 %r<7>;
.reg .b64 %rd<8>;


ld.param.u32 %r1, [_Z10testKerneli_param_0];
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %ntid.x;
mov.u32 %r4, %tid.x;
mad.lo.s32 %r5, %r2, %r3, %r4;
setp.lt.s32 %p1, %r5, %r1;
@%p1 bra $L__BB0_2;

mov.u64 %rd1, $str;
cvta.global.u64 %rd2, %rd1;
mov.u64 %rd3, $str$1;
cvta.global.u64 %rd4, %rd3;
mov.u64 %rd5, __unnamed_1;
cvta.global.u64 %rd6, %rd5;
mov.u32 %r6, 21;
mov.u64 %rd7, 1;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd2;
.param .b64 param1;
st.param.b64 [param1+0], %rd4;
.param .b32 param2;
st.param.b32 [param2+0], %r6;
.param .b64 param3;
st.param.b64 [param3+0], %rd6;
.param .b64 param4;
st.param.b64 [param4+0], %rd7;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB0_2:
ret;

}

.visible .entry _Z10perfKernelv()
{
.reg .pred %p<12>;
.reg .b32 %r<36>;
.reg .b64 %rd<43>;


mov.u32 %r17, %ctaid.x;
mov.u32 %r18, %ntid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r1, %r17, %r18, %r19;
mov.u32 %r20, %nctaid.x;
mul.lo.s32 %r21, %r18, %r20;
setp.le.u32 %p1, %r1, %r21;
@%p1 bra $L__BB1_2;

mov.u64 %rd1, $str$2;
cvta.global.u64 %rd2, %rd1;
mov.u64 %rd3, $str$1;
cvta.global.u64 %rd4, %rd3;
mov.u64 %rd5, __unnamed_2;
cvta.global.u64 %rd6, %rd5;
mov.u32 %r22, 28;
mov.u64 %rd7, 1;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd2;
.param .b64 param1;
st.param.b64 [param1+0], %rd4;
.param .b32 param2;
st.param.b32 [param2+0], %r22;
.param .b64 param3;
st.param.b64 [param3+0], %rd6;
.param .b64 param4;
st.param.b64 [param4+0], %rd7;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB1_2:
setp.lt.s32 %p2, %r1, 1;
@%p2 bra $L__BB1_19;

add.s32 %r24, %r1, -1;
and.b32 %r35, %r1, 3;
setp.lt.u32 %p3, %r24, 3;
mov.u32 %r34, 0;
@%p3 bra $L__BB1_14;

sub.s32 %r32, %r1, %r35;
mov.u32 %r31, 0;
mov.u64 %rd29, $str$3;
cvta.global.u64 %rd30, %rd29;
mov.u64 %rd31, $str$1;
cvta.global.u64 %rd32, %rd31;
mov.u64 %rd33, __unnamed_2;
cvta.global.u64 %rd34, %rd33;
mov.u64 %rd35, 1;

$L__BB1_5:
setp.lt.s32 %p4, %r31, %r1;
@%p4 bra $L__BB1_7;

mov.u32 %r26, 31;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd30;
.param .b64 param1;
st.param.b64 [param1+0], %rd32;
.param .b32 param2;
st.param.b32 [param2+0], %r26;
.param .b64 param3;
st.param.b64 [param3+0], %rd34;
.param .b64 param4;
st.param.b64 [param4+0], %rd35;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB1_7:
add.s32 %r6, %r31, 1;
setp.lt.s32 %p5, %r6, %r1;
@%p5 bra $L__BB1_9;

mov.u32 %r27, 31;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd30;
.param .b64 param1;
st.param.b64 [param1+0], %rd32;
.param .b32 param2;
st.param.b32 [param2+0], %r27;
.param .b64 param3;
st.param.b64 [param3+0], %rd34;
.param .b64 param4;
st.param.b64 [param4+0], %rd35;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB1_9:
add.s32 %r7, %r6, 1;
setp.lt.s32 %p6, %r7, %r1;
@%p6 bra $L__BB1_11;

mov.u32 %r28, 31;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd30;
.param .b64 param1;
st.param.b64 [param1+0], %rd32;
.param .b32 param2;
st.param.b32 [param2+0], %r28;
.param .b64 param3;
st.param.b64 [param3+0], %rd34;
.param .b64 param4;
st.param.b64 [param4+0], %rd35;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB1_11:
add.s32 %r8, %r7, 1;
setp.lt.s32 %p7, %r8, %r1;
@%p7 bra $L__BB1_13;

mov.u32 %r29, 31;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd30;
.param .b64 param1;
st.param.b64 [param1+0], %rd32;
.param .b32 param2;
st.param.b32 [param2+0], %r29;
.param .b64 param3;
st.param.b64 [param3+0], %rd34;
.param .b64 param4;
st.param.b64 [param4+0], %rd35;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB1_13:
add.s32 %r32, %r32, -4;
setp.ne.s32 %p8, %r32, 0;
add.s32 %r10, %r8, 1;
add.s32 %r34, %r31, 4;
mov.u32 %r31, %r10;
@%p8 bra $L__BB1_5;

$L__BB1_14:
setp.eq.s32 %p9, %r35, 0;
@%p9 bra $L__BB1_19;

mov.u64 %rd36, $str$3;
cvta.global.u64 %rd37, %rd36;
mov.u64 %rd38, $str$1;
cvta.global.u64 %rd39, %rd38;
mov.u64 %rd40, __unnamed_2;
cvta.global.u64 %rd41, %rd40;
mov.u64 %rd42, 1;

$L__BB1_16:
.pragma "nounroll";
setp.lt.s32 %p10, %r34, %r1;
@%p10 bra $L__BB1_18;

mov.u32 %r30, 31;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd37;
.param .b64 param1;
st.param.b64 [param1+0], %rd39;
.param .b32 param2;
st.param.b32 [param2+0], %r30;
.param .b64 param3;
st.param.b64 [param3+0], %rd41;
.param .b64 param4;
st.param.b64 [param4+0], %rd42;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB1_18:
add.s32 %r35, %r35, -1;
setp.ne.s32 %p11, %r35, 0;
add.s32 %r34, %r34, 1;
@%p11 bra $L__BB1_16;

$L__BB1_19:
ret;

}

.visible .entry _Z11perfKernel2v()
{
.reg .pred %p<11>;
.reg .b32 %r<33>;
.reg .b64 %rd<36>;


mov.u32 %r17, %ctaid.x;
mov.u32 %r18, %ntid.x;
mov.u32 %r19, %tid.x;
mad.lo.s32 %r1, %r17, %r18, %r19;
setp.lt.s32 %p1, %r1, 1;
@%p1 bra $L__BB2_17;

add.s32 %r21, %r1, -1;
and.b32 %r32, %r1, 3;
setp.lt.u32 %p2, %r21, 3;
mov.u32 %r31, 0;
@%p2 bra $L__BB2_12;

sub.s32 %r29, %r1, %r32;
mov.u32 %r28, 0;
mov.u64 %rd22, $str$3;
cvta.global.u64 %rd23, %rd22;
mov.u64 %rd24, $str$1;
cvta.global.u64 %rd25, %rd24;
mov.u64 %rd26, __unnamed_3;
cvta.global.u64 %rd27, %rd26;
mov.u64 %rd28, 1;

$L__BB2_3:
setp.lt.s32 %p3, %r28, %r1;
@%p3 bra $L__BB2_5;

mov.u32 %r23, 40;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd23;
.param .b64 param1;
st.param.b64 [param1+0], %rd25;
.param .b32 param2;
st.param.b32 [param2+0], %r23;
.param .b64 param3;
st.param.b64 [param3+0], %rd27;
.param .b64 param4;
st.param.b64 [param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB2_5:
add.s32 %r6, %r28, 1;
setp.lt.s32 %p4, %r6, %r1;
@%p4 bra $L__BB2_7;

mov.u32 %r24, 40;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd23;
.param .b64 param1;
st.param.b64 [param1+0], %rd25;
.param .b32 param2;
st.param.b32 [param2+0], %r24;
.param .b64 param3;
st.param.b64 [param3+0], %rd27;
.param .b64 param4;
st.param.b64 [param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB2_7:
add.s32 %r7, %r6, 1;
setp.lt.s32 %p5, %r7, %r1;
@%p5 bra $L__BB2_9;

mov.u32 %r25, 40;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd23;
.param .b64 param1;
st.param.b64 [param1+0], %rd25;
.param .b32 param2;
st.param.b32 [param2+0], %r25;
.param .b64 param3;
st.param.b64 [param3+0], %rd27;
.param .b64 param4;
st.param.b64 [param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB2_9:
add.s32 %r8, %r7, 1;
setp.lt.s32 %p6, %r8, %r1;
@%p6 bra $L__BB2_11;

mov.u32 %r26, 40;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd23;
.param .b64 param1;
st.param.b64 [param1+0], %rd25;
.param .b32 param2;
st.param.b32 [param2+0], %r26;
.param .b64 param3;
st.param.b64 [param3+0], %rd27;
.param .b64 param4;
st.param.b64 [param4+0], %rd28;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB2_11:
add.s32 %r29, %r29, -4;
setp.ne.s32 %p7, %r29, 0;
add.s32 %r10, %r8, 1;
add.s32 %r31, %r28, 4;
mov.u32 %r28, %r10;
@%p7 bra $L__BB2_3;

$L__BB2_12:
setp.eq.s32 %p8, %r32, 0;
@%p8 bra $L__BB2_17;

mov.u64 %rd29, $str$3;
cvta.global.u64 %rd30, %rd29;
mov.u64 %rd31, $str$1;
cvta.global.u64 %rd32, %rd31;
mov.u64 %rd33, __unnamed_3;
cvta.global.u64 %rd34, %rd33;
mov.u64 %rd35, 1;

$L__BB2_14:
.pragma "nounroll";
setp.lt.s32 %p9, %r31, %r1;
@%p9 bra $L__BB2_16;

mov.u32 %r27, 40;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd30;
.param .b64 param1;
st.param.b64 [param1+0], %rd32;
.param .b32 param2;
st.param.b32 [param2+0], %r27;
.param .b64 param3;
st.param.b64 [param3+0], %rd34;
.param .b64 param4;
st.param.b64 [param4+0], %rd35;
call.uni 
__assertfail, 
(
param0, 
param1, 
param2, 
param3, 
param4
);
} 

$L__BB2_16:
add.s32 %r32, %r32, -1;
setp.ne.s32 %p10, %r32, 0;
add.s32 %r31, %r31, 1;
@%p10 bra $L__BB2_14;

$L__BB2_17:
ret;

}

